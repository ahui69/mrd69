{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56d7bf3",
   "metadata": {},
   "source": [
    "# üèóÔ∏è Architektura i Niezawodno≈õƒá Systemu AI\n",
    "\n",
    "Kompleksowy blueprint implementacji system√≥w niezawodno≈õci, zarzƒÖdzania pamiƒôciƒÖ i kontekstem rozmowy dla zaawansowanego agenta AI.\n",
    "\n",
    "## üìã Spis tre≈õci\n",
    "\n",
    "1. **Twarde kontrakty na API pamiƒôci** - Guardy hasattr + metryki brak√≥w\n",
    "2. **Backpressure autopilota** - Limity tick√≥w + cooldown per kind\n",
    "3. **Idempotencja akcji** - Action_id z TTL\n",
    "4. **Retry policy** - 3 pr√≥by z eskalujƒÖcym timeoutem\n",
    "5. **Telemetria i KPI** - Metryki per tick + psychika monitoring\n",
    "6. **Uczenie adaptacyjne** - Reward shaping + autorefleksja\n",
    "7. **Presety trybow pracy** - Raid/Grinder/Monk + auto-preset\n",
    "8. **Higiena danych** - Dedup + TTL + snapshoty\n",
    "9. **LLM integracje** - Fallback + cache + szablony\n",
    "10. **Kontekst rozmowy** - Thread management + STM 10k znak√≥w\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927d86b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Konfiguracja systemu za≈Çadowana\n",
      "üìä STM Limits: 10000 chars, 100 lines\n",
      "üîÑ Autopilot: max 3 concurrent, 60.0s cooldown\n",
      "üîÅ Retry: 3 tries, base delay 1.0s\n"
     ]
    }
   ],
   "source": [
    "# Importy i konfiguracja podstawowa\n",
    "import hashlib\n",
    "import re\n",
    "import threading\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "from dataclasses import dataclass, field\n",
    "from functools import wraps\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "# Konfiguracja systemowa\n",
    "@dataclass\n",
    "class SystemConfig:\n",
    "    # Limity STM\n",
    "    STM_CHAR_LIMIT: int = 10000\n",
    "    STM_LINE_LIMIT: int = 100\n",
    "    STM_SUMMARY_INTERVAL: int = 25\n",
    "    STM_COMPRESSION_RATIO: float = 0.05\n",
    "    \n",
    "    # Autopilot backpressure\n",
    "    MAX_CONCURRENT_TICKS: int = 3\n",
    "    COOLDOWN_PER_KIND: float = 60.0  # sekund\n",
    "    ACTION_TTL: float = 3600.0  # 1 godzina\n",
    "    \n",
    "    # Retry policy\n",
    "    MAX_RETRIES: int = 3\n",
    "    RETRY_BASE_DELAY: float = 1.0\n",
    "    RETRY_MULTIPLIER: float = 2.0\n",
    "    \n",
    "    # Telemetria\n",
    "    TELEMETRY_BATCH_SIZE: int = 50\n",
    "    LOG_MAX_SIZE_MB: int = 10\n",
    "    SNAPSHOT_INTERVAL: int = 300  # 5 minut\n",
    "    \n",
    "    # Jako≈õƒá i thresholds\n",
    "    REFLECTION_THRESHOLD_LOW: float = 0.4\n",
    "    REFLECTION_THRESHOLD_HIGH: float = 0.7\n",
    "    DUPLICATE_SIMILARITY_THRESHOLD: float = 0.8\n",
    "    ETHICAL_CONCERN_THRESHOLD: float = 0.6\n",
    "\n",
    "CONFIG = SystemConfig()\n",
    "\n",
    "print(\"‚úÖ Konfiguracja systemu za≈Çadowana\")\n",
    "print(f\"üìä STM Limits: {CONFIG.STM_CHAR_LIMIT} chars, {CONFIG.STM_LINE_LIMIT} lines\")\n",
    "print(f\"üîÑ Autopilot: max {CONFIG.MAX_CONCURRENT_TICKS} concurrent, {CONFIG.COOLDOWN_PER_KIND}s cooldown\")\n",
    "print(f\"üîÅ Retry: {CONFIG.MAX_RETRIES} tries, base delay {CONFIG.RETRY_BASE_DELAY}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a0757",
   "metadata": {},
   "source": [
    "## üîê 1. Twarde kontrakty na API pamiƒôci\n",
    "\n",
    "System guardy `hasattr` dla metod must-have API pamiƒôci z metrykami brak√≥w i fallbackami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55341ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Walidacja API pamiƒôci:\n",
      "  ‚úÖ add_fact: Dodawanie fakt√≥w do pamiƒôci\n",
      "  ‚úÖ get_goals: Pobieranie cel√≥w u≈ºytkownika\n",
      "  ‚ùå compose_context: Sk≈Çadanie kontekstu dla LLM\n",
      "  ‚ùå get_profile: Pobieranie profilu u≈ºytkownika\n",
      "  ‚ùå set_profile_many: Zapisywanie wielu warto≈õci profilu\n",
      "\n",
      "üìä Metryki po testach: {'total_calls': 3, 'fallback_usage': 2, 'fallback_rate': 0.6666666666666666, 'missing_methods': {'compose_context': 2, 'get_profile': 2, 'set_profile_many': 1}, 'fallback_by_method': {'compose_context': 1, 'get_profile': 1}, 'coverage': {'add_fact': 1.0, 'get_goals': 1.0, 'compose_context': -1.0, 'get_profile': -1.0, 'set_profile_many': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "class MemoryAPIContract:\n",
    "    \"\"\"Twarde kontrakty na API pamiƒôci z metrykami brak√≥w\"\"\"\n",
    "    \n",
    "    REQUIRED_METHODS = {\n",
    "        'add_fact': 'Dodawanie fakt√≥w do pamiƒôci',\n",
    "        'get_goals': 'Pobieranie cel√≥w u≈ºytkownika', \n",
    "        'compose_context': 'Sk≈Çadanie kontekstu dla LLM',\n",
    "        'get_profile': 'Pobieranie profilu u≈ºytkownika',\n",
    "        'set_profile_many': 'Zapisywanie wielu warto≈õci profilu'\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.missing_methods_count = defaultdict(int)\n",
    "        self.fallback_usage_count = defaultdict(int)\n",
    "        self.total_calls = defaultdict(int)\n",
    "    \n",
    "    def validate_memory_object(self, memory_obj) -> dict[str, bool]:\n",
    "        \"\"\"Sprawdza obecno≈õƒá wymaganych metod w obiekcie pamiƒôci\"\"\"\n",
    "        validation_result = {}\n",
    "        \n",
    "        for method_name in self.REQUIRED_METHODS:\n",
    "            has_method = hasattr(memory_obj, method_name) and callable(getattr(memory_obj, method_name))\n",
    "            validation_result[method_name] = has_method\n",
    "            \n",
    "            if not has_method:\n",
    "                self.missing_methods_count[method_name] += 1\n",
    "                \n",
    "        return validation_result\n",
    "    \n",
    "    def safe_call(self, memory_obj, method_name: str, *args, **kwargs) -> Any:\n",
    "        \"\"\"Bezpieczne wywo≈Çanie metody z fallbackiem\"\"\"\n",
    "        self.total_calls[method_name] += 1\n",
    "        \n",
    "        if hasattr(memory_obj, method_name):\n",
    "            try:\n",
    "                return getattr(memory_obj, method_name)(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è B≈ÇƒÖd wywo≈Çania {method_name}: {e}\")\n",
    "                self.fallback_usage_count[method_name] += 1\n",
    "                return self._fallback_implementation(method_name, *args, **kwargs)\n",
    "        else:\n",
    "            self.missing_methods_count[method_name] += 1\n",
    "            self.fallback_usage_count[method_name] += 1\n",
    "            return self._fallback_implementation(method_name, *args, **kwargs)\n",
    "    \n",
    "    def _fallback_implementation(self, method_name: str, *args, **kwargs) -> Any:\n",
    "        \"\"\"Implementacje fallback dla brakujƒÖcych metod\"\"\"\n",
    "        fallbacks = {\n",
    "            'add_fact': lambda *a, **k: {'status': 'fallback', 'method': 'add_fact'},\n",
    "            'get_goals': lambda *a, **k: ['[FALLBACK] Podstawowy cel systemu'],\n",
    "            'compose_context': lambda *a, **k: '[FALLBACK] Ograniczony kontekst',\n",
    "            'get_profile': lambda *a, **k: {},\n",
    "            'set_profile_many': lambda *a, **k: {'saved': 0}\n",
    "        }\n",
    "        \n",
    "        if method_name in fallbacks:\n",
    "            return fallbacks[method_name](*args, **kwargs)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_metrics(self) -> dict[str, Any]:\n",
    "        \"\"\"Zwraca metryki brak√≥w API\"\"\"\n",
    "        total = sum(self.total_calls.values())\n",
    "        fallback_total = sum(self.fallback_usage_count.values())\n",
    "        \n",
    "        return {\n",
    "            'total_calls': total,\n",
    "            'fallback_usage': fallback_total,\n",
    "            'fallback_rate': fallback_total / max(total, 1),\n",
    "            'missing_methods': dict(self.missing_methods_count),\n",
    "            'fallback_by_method': dict(self.fallback_usage_count),\n",
    "            'coverage': {\n",
    "                method: 1 - (self.missing_methods_count[method] / max(self.total_calls[method], 1))\n",
    "                for method in self.REQUIRED_METHODS\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Test systemu kontrakt√≥w\n",
    "memory_contract = MemoryAPIContract()\n",
    "\n",
    "# Symulacja obiektu pamiƒôci z brakami\n",
    "class MockMemory:\n",
    "    def add_fact(self, fact): return {'saved': True}\n",
    "    def get_goals(self): return ['Cel 1', 'Cel 2']\n",
    "    # Brakuje: compose_context, get_profile, set_profile_many\n",
    "\n",
    "mock_memory = MockMemory()\n",
    "validation = memory_contract.validate_memory_object(mock_memory)\n",
    "\n",
    "print(\"üîç Walidacja API pamiƒôci:\")\n",
    "for method, available in validation.items():\n",
    "    status = \"‚úÖ\" if available else \"‚ùå\"\n",
    "    print(f\"  {status} {method}: {memory_contract.REQUIRED_METHODS[method]}\")\n",
    "\n",
    "# Test bezpiecznych wywo≈Ça≈Ñ\n",
    "result1 = memory_contract.safe_call(mock_memory, 'add_fact', 'test fact')\n",
    "result2 = memory_contract.safe_call(mock_memory, 'compose_context', 'test context')\n",
    "result3 = memory_contract.safe_call(mock_memory, 'get_profile')\n",
    "\n",
    "print(\"\\nüìä Metryki po testach:\", memory_contract.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a29b5",
   "metadata": {},
   "source": [
    "## üåä 2. Backpressure na autopilocie\n",
    "\n",
    "System limit√≥w r√≥wnoleg≈Çych tick√≥w i cooldown per kind dla kontroli przep≈Çywu autopilota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2a41f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Test systemu backpressure autopilota:\n",
      "‚úÖ tick_001 rozpoczƒôty\n",
      "üö´ Tick tick_002 odrzucony: Cooldown dla 'code_review': 5.0s pozosta≈Ço\n",
      "üîÑ tick_002 odrzucony (cooldown)\n",
      "‚úÖ tick_003 rozpoczƒôty\n",
      "üö´ Tick tick_004 odrzucony: Limit r√≥wnoleg≈Çych tick√≥w (2)\n",
      "üö´ tick_004 odrzucony (limit concurrent)\n",
      "\n",
      "üìä Status backpressure: {'active_ticks': 2, 'max_concurrent': 2, 'utilization': 1.0, 'total_requests': 4, 'rejected_count': {'cooldown': 1, 'concurrent_limit': 1}, 'rejection_rate': 0.5, 'kind_cooldowns': {'code_review': 4.999551057815552, 'documentation': 4.99980092048645}}\n",
      "\n",
      "‚è±Ô∏è Tick durations: tick_001=0.00s, tick_003=0.00s\n"
     ]
    }
   ],
   "source": [
    "class AutopilotBackpressure:\n",
    "    \"\"\"System kontroli przep≈Çywu autopilota z limitami i cooldown\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent: int = None, cooldown_per_kind: float = None):\n",
    "        self.max_concurrent = max_concurrent or CONFIG.MAX_CONCURRENT_TICKS\n",
    "        self.cooldown_per_kind = cooldown_per_kind or CONFIG.COOLDOWN_PER_KIND\n",
    "        \n",
    "        self.active_ticks = set()  # Set aktywnych tick_id\n",
    "        self.kind_last_executed = {}  # kind -> timestamp ostatniego wykonania\n",
    "        self.tick_start_times = {}  # tick_id -> start_time\n",
    "        self.rejected_count = defaultdict(int)\n",
    "        self.total_requests = 0\n",
    "        \n",
    "        self._lock = threading.Lock()\n",
    "    \n",
    "    def can_execute_tick(self, tick_id: str, action_kind: str) -> tuple[bool, str]:\n",
    "        \"\"\"Sprawdza czy tick mo≈ºe zostaƒá wykonany\"\"\"\n",
    "        with self._lock:\n",
    "            self.total_requests += 1\n",
    "            now = time.time()\n",
    "            \n",
    "            # Sprawd≈∫ limit r√≥wnoleg≈Çych tick√≥w\n",
    "            if len(self.active_ticks) >= self.max_concurrent:\n",
    "                self.rejected_count['concurrent_limit'] += 1\n",
    "                return False, f\"Limit r√≥wnoleg≈Çych tick√≥w ({self.max_concurrent})\"\n",
    "            \n",
    "            # Sprawd≈∫ cooldown dla tego kind\n",
    "            last_executed = self.kind_last_executed.get(action_kind, 0)\n",
    "            time_since_last = now - last_executed\n",
    "            \n",
    "            if time_since_last < self.cooldown_per_kind:\n",
    "                remaining = self.cooldown_per_kind - time_since_last\n",
    "                self.rejected_count['cooldown'] += 1\n",
    "                return False, f\"Cooldown dla '{action_kind}': {remaining:.1f}s pozosta≈Ço\"\n",
    "            \n",
    "            return True, \"OK\"\n",
    "    \n",
    "    def start_tick(self, tick_id: str, action_kind: str) -> bool:\n",
    "        \"\"\"Rozpoczyna wykonanie tick-a\"\"\"\n",
    "        can_execute, reason = self.can_execute_tick(tick_id, action_kind)\n",
    "        \n",
    "        if can_execute:\n",
    "            with self._lock:\n",
    "                self.active_ticks.add(tick_id)\n",
    "                self.tick_start_times[tick_id] = time.time()\n",
    "                self.kind_last_executed[action_kind] = time.time()\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"üö´ Tick {tick_id} odrzucony: {reason}\")\n",
    "            return False\n",
    "    \n",
    "    def finish_tick(self, tick_id: str) -> float | None:\n",
    "        \"\"\"Ko≈Ñczy wykonanie tick-a i zwraca czas trwania\"\"\"\n",
    "        with self._lock:\n",
    "            if tick_id in self.active_ticks:\n",
    "                self.active_ticks.remove(tick_id)\n",
    "                start_time = self.tick_start_times.pop(tick_id, time.time())\n",
    "                duration = time.time() - start_time\n",
    "                return duration\n",
    "            return None\n",
    "    \n",
    "    def cleanup_stale_ticks(self, max_duration: float = 300.0):\n",
    "        \"\"\"Usuwa tick-i kt√≥re trwajƒÖ zbyt d≈Çugo (zombie cleanup)\"\"\"\n",
    "        now = time.time()\n",
    "        stale_ticks = []\n",
    "        \n",
    "        with self._lock:\n",
    "            for tick_id, start_time in self.tick_start_times.items():\n",
    "                if now - start_time > max_duration:\n",
    "                    stale_ticks.append(tick_id)\n",
    "            \n",
    "            for tick_id in stale_ticks:\n",
    "                if tick_id in self.active_ticks:\n",
    "                    self.active_ticks.remove(tick_id)\n",
    "                    self.tick_start_times.pop(tick_id, None)\n",
    "                    print(f\"üßπ Usuniƒôto sta≈Çy tick: {tick_id}\")\n",
    "    \n",
    "    def get_status(self) -> dict[str, Any]:\n",
    "        \"\"\"Zwraca status systemu backpressure\"\"\"\n",
    "        with self._lock:\n",
    "            return {\n",
    "                'active_ticks': len(self.active_ticks),\n",
    "                'max_concurrent': self.max_concurrent,\n",
    "                'utilization': len(self.active_ticks) / self.max_concurrent,\n",
    "                'total_requests': self.total_requests,\n",
    "                'rejected_count': dict(self.rejected_count),\n",
    "                'rejection_rate': sum(self.rejected_count.values()) / max(self.total_requests, 1),\n",
    "                'kind_cooldowns': {\n",
    "                    kind: max(0, self.cooldown_per_kind - (time.time() - last_time))\n",
    "                    for kind, last_time in self.kind_last_executed.items()\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Test systemu backpressure\n",
    "backpressure = AutopilotBackpressure(max_concurrent=2, cooldown_per_kind=5.0)\n",
    "\n",
    "print(\"üöÄ Test systemu backpressure autopilota:\")\n",
    "\n",
    "# Test 1: Normalne wykonanie\n",
    "tick1_id = \"tick_001\"\n",
    "if backpressure.start_tick(tick1_id, \"code_review\"):\n",
    "    print(f\"‚úÖ {tick1_id} rozpoczƒôty\")\n",
    "    \n",
    "# Test 2: Ten sam kind - powinien byƒá odrzucony\n",
    "tick2_id = \"tick_002\"\n",
    "if not backpressure.start_tick(tick2_id, \"code_review\"):\n",
    "    print(f\"üîÑ {tick2_id} odrzucony (cooldown)\")\n",
    "\n",
    "# Test 3: Inny kind - powinien przej≈õƒá\n",
    "tick3_id = \"tick_003\"\n",
    "if backpressure.start_tick(tick3_id, \"documentation\"):\n",
    "    print(f\"‚úÖ {tick3_id} rozpoczƒôty\")\n",
    "\n",
    "# Test 4: Limit concurrent - powinien byƒá odrzucony\n",
    "tick4_id = \"tick_004\"\n",
    "if not backpressure.start_tick(tick4_id, \"testing\"):\n",
    "    print(f\"üö´ {tick4_id} odrzucony (limit concurrent)\")\n",
    "\n",
    "# Statusy\n",
    "print(\"\\nüìä Status backpressure:\", backpressure.get_status())\n",
    "\n",
    "# Cleanup\n",
    "duration1 = backpressure.finish_tick(tick1_id)\n",
    "duration3 = backpressure.finish_tick(tick3_id)\n",
    "print(f\"\\n‚è±Ô∏è Tick durations: {tick1_id}={duration1:.2f}s, {tick3_id}={duration3:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57f6515",
   "metadata": {},
   "source": [
    "## üîÑ 3. Idempotencja akcji\n",
    "\n",
    "System action_id z hashem kind+title i TTL dla unikania duplikat√≥w akcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12e4b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Test systemu idempotencji akcji:\n",
      "‚ú® Nowa akcja 1b643d609a82: code_review - Review user authentication\n",
      "üîÑ Duplikat 1b643d609a82: confidence 1.00, count 2\n",
      "‚ú® Nowa akcja 4b0c6c8e1ec6: code_review - Review user authorization\n",
      "üîÑ Duplikat 1b643d609a82: confidence 1.00, count 3\n",
      "\n",
      "üÜî Generated IDs: 1b643d609a82, 1b643d609a82, 4b0c6c8e1ec6, 1b643d609a82\n",
      "üîó ID1==ID2: True, ID1==ID3: False, ID1==ID4: True\n",
      "üìã 1b643d609a82: count=3, confidence=1.00\n",
      "üìã 4b0c6c8e1ec6: count=1, confidence=0.90\n",
      "\n",
      "üìä Statystyki idempotencji: {'total_registered': 2, 'active_count': 2, 'duplicate_rate': 0.5, 'avg_confidence': 0.95, 'top_kinds': {'code_review': 1}}\n"
     ]
    }
   ],
   "source": [
    "class ActionIdempotency:\n",
    "    \"\"\"System idempotencji akcji z action_id i TTL\"\"\"\n",
    "    \n",
    "    def __init__(self, ttl: float = None):\n",
    "        self.ttl = ttl or CONFIG.ACTION_TTL\n",
    "        self.action_registry = {}  # action_id -> {'timestamp', 'confidence', 'count', 'data'}\n",
    "        self.cleanup_counter = 0\n",
    "        \n",
    "    def generate_action_id(self, action: dict[str, Any]) -> str:\n",
    "        \"\"\"Generuje action_id z hashem kind+title\"\"\"\n",
    "        kind = action.get('kind', 'unknown')\n",
    "        title = action.get('title', action.get('description', 'untitled'))\n",
    "        \n",
    "        # Normalizacja dla stabilno≈õci hash-a\n",
    "        normalized = f\"{kind.lower().strip()}:{title.lower().strip()}\"\n",
    "        return hashlib.md5(normalized.encode('utf-8')).hexdigest()[:12]\n",
    "    \n",
    "    def is_duplicate(self, action: dict[str, Any]) -> tuple[bool, dict | None]:\n",
    "        \"\"\"Sprawdza czy akcja jest duplikatem w oknie TTL\"\"\"\n",
    "        action_id = self.generate_action_id(action)\n",
    "        now = time.time()\n",
    "        \n",
    "        # Cleanup co 100 sprawdze≈Ñ\n",
    "        self.cleanup_counter += 1\n",
    "        if self.cleanup_counter % 100 == 0:\n",
    "            self._cleanup_expired()\n",
    "        \n",
    "        if action_id in self.action_registry:\n",
    "            entry = self.action_registry[action_id]\n",
    "            \n",
    "            # Sprawd≈∫ czy nie wygas≈Ç\n",
    "            if now - entry['timestamp'] < self.ttl:\n",
    "                return True, entry\n",
    "            else:\n",
    "                # Wygas≈Ç - usu≈Ñ\n",
    "                del self.action_registry[action_id]\n",
    "        \n",
    "        return False, None\n",
    "    \n",
    "    def register_action(self, action: dict[str, Any], confidence: float = 1.0) -> str:\n",
    "        \"\"\"Rejestruje akcjƒô lub podwy≈ºsza confidence je≈õli duplikat\"\"\"\n",
    "        action_id = self.generate_action_id(action)\n",
    "        now = time.time()\n",
    "        \n",
    "        is_dup, existing = self.is_duplicate(action)\n",
    "        \n",
    "        if is_dup and existing:\n",
    "            # Podnie≈õ confidence i count dla duplikatu\n",
    "            existing['confidence'] = min(1.0, existing['confidence'] + confidence * 0.3)\n",
    "            existing['count'] += 1\n",
    "            existing['last_seen'] = now\n",
    "            print(f\"üîÑ Duplikat {action_id}: confidence {existing['confidence']:.2f}, count {existing['count']}\")\n",
    "            return action_id\n",
    "        else:\n",
    "            # Nowa akcja\n",
    "            self.action_registry[action_id] = {\n",
    "                'timestamp': now,\n",
    "                'last_seen': now,\n",
    "                'confidence': confidence,\n",
    "                'count': 1,\n",
    "                'data': {\n",
    "                    'kind': action.get('kind'),\n",
    "                    'title': action.get('title', action.get('description')),\n",
    "                    'impact': action.get('impact'),\n",
    "                }\n",
    "            }\n",
    "            print(f\"‚ú® Nowa akcja {action_id}: {action.get('kind')} - {action.get('title', 'untitled')}\")\n",
    "            return action_id\n",
    "    \n",
    "    def get_action_info(self, action_id: str) -> dict | None:\n",
    "        \"\"\"Zwraca info o akcji\"\"\"\n",
    "        return self.action_registry.get(action_id)\n",
    "    \n",
    "    def _cleanup_expired(self):\n",
    "        \"\"\"Usuwa wygas≈Çe akcje\"\"\"\n",
    "        now = time.time()\n",
    "        expired = [\n",
    "            action_id for action_id, entry in self.action_registry.items()\n",
    "            if now - entry['timestamp'] > self.ttl\n",
    "        ]\n",
    "        \n",
    "        for action_id in expired:\n",
    "            del self.action_registry[action_id]\n",
    "        \n",
    "        if expired:\n",
    "            print(f\"üßπ Usuniƒôto {len(expired)} wygas≈Çych akcji\")\n",
    "    \n",
    "    def get_stats(self) -> dict[str, Any]:\n",
    "        \"\"\"Zwraca statystyki systemu idempotencji\"\"\"\n",
    "        now = time.time()\n",
    "        active_actions = [\n",
    "            entry for entry in self.action_registry.values()\n",
    "            if now - entry['timestamp'] < self.ttl\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            'total_registered': len(self.action_registry),\n",
    "            'active_count': len(active_actions),\n",
    "            'duplicate_rate': sum(1 for e in active_actions if e['count'] > 1) / max(len(active_actions), 1),\n",
    "            'avg_confidence': sum(e['confidence'] for e in active_actions) / max(len(active_actions), 1),\n",
    "            'top_kinds': {\n",
    "                entry['data']['kind']: entry['count'] \n",
    "                for entry in sorted(active_actions, key=lambda x: x['count'], reverse=True)[:5]\n",
    "                if entry['data']['kind']\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Test systemu idempotencji\n",
    "idempotency = ActionIdempotency(ttl=10.0)  # 10 sekund dla testu\n",
    "\n",
    "print(\"üîÑ Test systemu idempotencji akcji:\")\n",
    "\n",
    "# Test 1: Nowa akcja\n",
    "action1 = {'kind': 'code_review', 'title': 'Review user authentication', 'impact': 0.8}\n",
    "id1 = idempotency.register_action(action1, confidence=0.9)\n",
    "\n",
    "# Test 2: Duplikat tej samej akcji\n",
    "action2 = {'kind': 'code_review', 'title': 'Review user authentication', 'impact': 0.7}\n",
    "id2 = idempotency.register_action(action2, confidence=0.8)\n",
    "\n",
    "# Test 3: Podobna ale inna akcja  \n",
    "action3 = {'kind': 'code_review', 'title': 'Review user authorization', 'impact': 0.8}\n",
    "id3 = idempotency.register_action(action3, confidence=0.9)\n",
    "\n",
    "# Test 4: Jeszcze jeden duplikat pierwszej\n",
    "action4 = {'kind': 'Code_Review', 'title': ' Review User Authentication ', 'impact': 0.6}  # r√≥≈ºne case i spacje\n",
    "id4 = idempotency.register_action(action4, confidence=0.7)\n",
    "\n",
    "print(f\"\\nüÜî Generated IDs: {id1}, {id2}, {id3}, {id4}\")\n",
    "print(f\"üîó ID1==ID2: {id1 == id2}, ID1==ID3: {id1 == id3}, ID1==ID4: {id1 == id4}\")\n",
    "\n",
    "# Info o akcjach\n",
    "for action_id in [id1, id3]:\n",
    "    info = idempotency.get_action_info(action_id)\n",
    "    if info:\n",
    "        print(f\"üìã {action_id}: count={info['count']}, confidence={info['confidence']:.2f}\")\n",
    "\n",
    "print(\"\\nüìä Statystyki idempotencji:\", idempotency.get_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc98ffa",
   "metadata": {},
   "source": [
    "## üîÅ 4. System retry policy\n",
    "\n",
    "Implementacja 3 pr√≥b z eskalujƒÖcym timeoutem i zapisem b≈Çƒôd√≥w do pamiƒôci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0aefc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Test systemu retry policy:\n",
      "\n",
      "üìã Test 1: Sukces po 2 pr√≥bach\n",
      "üîÑ Retry 1/3 dla flaky_llm_call: LLM connection failed (attempt 1)\n",
      "‚è≥ Czekam 0.1s przed kolejnƒÖ pr√≥bƒÖ...\n",
      "‚úÖ Sukces flaky_llm_call po 1 pr√≥bach (ostatni b≈ÇƒÖd: LLM connection failed (attempt 1))\n",
      "‚úÖ Rezultat: LLM response to: Generate code review (succeeded on attempt 2)\n",
      "\n",
      "üìã Test 2: Ostateczna pora≈ºka\n",
      "üîÑ Retry 1/2 dla flaky_io_operation: File operation failed: config.json (attempt 1)\n",
      "‚è≥ Czekam 0.1s przed kolejnƒÖ pr√≥bƒÖ...\n",
      "üîÑ Retry 2/2 dla flaky_io_operation: File operation failed: config.json (attempt 2)\n",
      "‚è≥ Czekam 0.1s przed kolejnƒÖ pr√≥bƒÖ...\n",
      "‚ùå flaky_io_operation nie powi√≥d≈Ç siƒô po 2 pr√≥bach: File operation failed: config.json (attempt 3)\n",
      "‚ùå Ostateczny b≈ÇƒÖd: File operation failed: config.json (attempt 3)\n",
      "\n",
      "üìã Test 3: Natychmiastowy sukces\n",
      "‚úÖ Rezultat: LLM response to: Quick task (succeeded on attempt 1)\n"
     ]
    }
   ],
   "source": [
    "def retry_with_backoff(max_retries: int = None, base_delay: float = None, multiplier: float = None):\n",
    "    \"\"\"Decorator dla retry policy z eskalujƒÖcym op√≥≈∫nieniem\"\"\"\n",
    "    \n",
    "    max_retries = max_retries or CONFIG.MAX_RETRIES\n",
    "    base_delay = base_delay or CONFIG.RETRY_BASE_DELAY\n",
    "    multiplier = multiplier or CONFIG.RETRY_MULTIPLIER\n",
    "    \n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_exception = None\n",
    "            \n",
    "            for attempt in range(max_retries + 1):  # +1 bo liczymy od 0\n",
    "                try:\n",
    "                    result = func(*args, **kwargs)\n",
    "                    \n",
    "                    # Zapisz sukces po retry\n",
    "                    if attempt > 0:\n",
    "                        _log_retry_success(func.__name__, attempt, last_exception)\n",
    "                    \n",
    "                    return result\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    last_exception = e\n",
    "                    \n",
    "                    if attempt == max_retries:\n",
    "                        # Ostatnia pr√≥ba - zapisz b≈ÇƒÖd i propaguj\n",
    "                        _log_retry_failure(func.__name__, max_retries, e)\n",
    "                        raise e\n",
    "                    \n",
    "                    # Oblicz op√≥≈∫nienie z eksponentialnym backoff\n",
    "                    delay = base_delay * (multiplier ** attempt)\n",
    "                    \n",
    "                    print(f\"üîÑ Retry {attempt + 1}/{max_retries} dla {func.__name__}: {e}\")\n",
    "                    print(f\"‚è≥ Czekam {delay:.1f}s przed kolejnƒÖ pr√≥bƒÖ...\")\n",
    "                    \n",
    "                    time.sleep(delay)\n",
    "            \n",
    "            # Tego nigdy nie powinni≈õmy osiƒÖgnƒÖƒá\n",
    "            raise last_exception\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def _log_retry_success(func_name: str, attempts: int, last_error: Exception):\n",
    "    \"\"\"Loguje sukces po retry\"\"\"\n",
    "    print(f\"‚úÖ Sukces {func_name} po {attempts} pr√≥bach (ostatni b≈ÇƒÖd: {last_error})\")\n",
    "    # Tu doda≈Çby≈õ zapis do memory z tagiem \"retry:success\"\n",
    "\n",
    "def _log_retry_failure(func_name: str, max_attempts: int, final_error: Exception):\n",
    "    \"\"\"Loguje ostateczny b≈ÇƒÖd retry\"\"\"\n",
    "    error_type = \"llm\" if \"llm\" in str(final_error).lower() else \"io\"\n",
    "    print(f\"‚ùå {func_name} nie powi√≥d≈Ç siƒô po {max_attempts} pr√≥bach: {final_error}\")\n",
    "    # Tu doda≈Çby≈õ zapis do memory z tagiem f\"error:{error_type}\"\n",
    "\n",
    "class RetryPolicyTester:\n",
    "    \"\"\"Klasa do testowania retry policy\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.call_count = 0\n",
    "        self.should_fail_until = 0\n",
    "    \n",
    "    @retry_with_backoff(max_retries=3, base_delay=0.1, multiplier=2.0)\n",
    "    def flaky_llm_call(self, prompt: str) -> str:\n",
    "        \"\"\"Symuluje niestabilne wywo≈Çanie LLM\"\"\"\n",
    "        self.call_count += 1\n",
    "        \n",
    "        if self.call_count <= self.should_fail_until:\n",
    "            if self.call_count % 2 == 1:\n",
    "                raise ConnectionError(f\"LLM connection failed (attempt {self.call_count})\")\n",
    "            else:\n",
    "                raise TimeoutError(f\"LLM timeout (attempt {self.call_count})\")\n",
    "        \n",
    "        return f\"LLM response to: {prompt} (succeeded on attempt {self.call_count})\"\n",
    "    \n",
    "    @retry_with_backoff(max_retries=2, base_delay=0.05, multiplier=1.5)\n",
    "    def flaky_io_operation(self, filename: str) -> dict:\n",
    "        \"\"\"Symuluje niestabilnƒÖ operacjƒô I/O\"\"\"\n",
    "        self.call_count += 1\n",
    "        \n",
    "        if self.call_count <= self.should_fail_until:\n",
    "            raise OSError(f\"File operation failed: {filename} (attempt {self.call_count})\")\n",
    "        \n",
    "        return {\"status\": \"success\", \"file\": filename, \"attempt\": self.call_count}\n",
    "\n",
    "# Test retry policy\n",
    "print(\"üîÅ Test systemu retry policy:\")\n",
    "\n",
    "tester = RetryPolicyTester()\n",
    "\n",
    "# Test 1: Sukces po 2 pr√≥bach\n",
    "print(\"\\nüìã Test 1: Sukces po 2 pr√≥bach\")\n",
    "tester.call_count = 0\n",
    "tester.should_fail_until = 1  # Fail na pierwszej pr√≥bie, sukces na drugiej\n",
    "\n",
    "try:\n",
    "    result = tester.flaky_llm_call(\"Generate code review\")\n",
    "    print(f\"‚úÖ Rezultat: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå B≈ÇƒÖd: {e}\")\n",
    "\n",
    "# Test 2: Ostateczna pora≈ºka po wszystkich pr√≥bach\n",
    "print(\"\\nüìã Test 2: Ostateczna pora≈ºka\")\n",
    "tester.call_count = 0\n",
    "tester.should_fail_until = 10  # Zawsze fail\n",
    "\n",
    "try:\n",
    "    result = tester.flaky_io_operation(\"config.json\")\n",
    "    print(f\"‚úÖ Rezultat: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ostateczny b≈ÇƒÖd: {e}\")\n",
    "\n",
    "# Test 3: Natychmiastowy sukces\n",
    "print(\"\\nüìã Test 3: Natychmiastowy sukces\")\n",
    "tester.call_count = 0  \n",
    "tester.should_fail_until = 0  # Nie fail wcale\n",
    "\n",
    "try:\n",
    "    result = tester.flaky_llm_call(\"Quick task\")\n",
    "    print(f\"‚úÖ Rezultat: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå B≈ÇƒÖd: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ab426",
   "metadata": {},
   "source": [
    "## üìä 5. Telemetria per tick\n",
    "\n",
    "System zapisywania metryk tick√≥w do pamiƒôci: liczba propozycji, score, akceptacje, czas LLM, b≈Çƒôdy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "008d8a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Test systemu telemetrii per tick:\n",
      "üìà Telemetria tick_001:\n",
      "   Proposals: 3, avg score: 0.70\n",
      "   Acceptance rate: 0.67\n",
      "   LLM: 2 calls, avg 1.00s\n",
      "   Errors: 1\n",
      "üì§ Flush telemetrii: 3 tick-√≥w\n",
      "   ≈örednia proposals: 1.7\n",
      "   ≈örednia acceptance rate: 0.22\n",
      "   ≈öredni czas LLM: 0.33s\n",
      "\n",
      "üìä Rolling metrics: {'window_size': 3, 'avg_proposals_per_tick': 1.6666666666666667, 'avg_acceptance_rate': 0.2222222222222222, 'avg_llm_time': 0.3333333333333333, 'avg_tick_duration': 0.0006223519643147787, 'error_rate': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class TickTelemetry:\n",
    "    \"\"\"Telemetria pojedynczego tick-a autopilota\"\"\"\n",
    "    tick_id: str\n",
    "    timestamp: float\n",
    "    \n",
    "    # Propozycje\n",
    "    proposals_count: int = 0\n",
    "    proposals_avg_score: float = 0.0\n",
    "    proposals_kinds: list[str] = field(default_factory=list)\n",
    "    \n",
    "    # Decyzje\n",
    "    accepted_count: int = 0\n",
    "    rejected_count: int = 0\n",
    "    acceptance_rate: float = 0.0\n",
    "    \n",
    "    # Performance\n",
    "    llm_calls: int = 0\n",
    "    llm_total_time: float = 0.0\n",
    "    llm_avg_time: float = 0.0\n",
    "    total_duration: float = 0.0\n",
    "    \n",
    "    # B≈Çƒôdy\n",
    "    errors: list[dict[str, Any]] = field(default_factory=list)\n",
    "    error_count: int = 0\n",
    "    \n",
    "    # Kontekst\n",
    "    context_size_chars: int = 0\n",
    "    memory_facts_used: int = 0\n",
    "\n",
    "class TelemetryCollector:\n",
    "    \"\"\"Kolektor telemetrii systemu\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size: int = None):\n",
    "        self.batch_size = batch_size or CONFIG.TELEMETRY_BATCH_SIZE\n",
    "        self.telemetry_batch = []\n",
    "        self.metrics_summary = defaultdict(list)\n",
    "        \n",
    "    def start_tick_telemetry(self, tick_id: str) -> TickTelemetry:\n",
    "        \"\"\"Rozpoczyna zbieranie telemetrii dla tick-a\"\"\"\n",
    "        return TickTelemetry(\n",
    "            tick_id=tick_id,\n",
    "            timestamp=time.time()\n",
    "        )\n",
    "    \n",
    "    def record_proposals(self, telemetry: TickTelemetry, proposals: list[dict]):\n",
    "        \"\"\"Rejestruje propozycje w telemetrii\"\"\"\n",
    "        telemetry.proposals_count = len(proposals)\n",
    "        \n",
    "        if proposals:\n",
    "            scores = [p.get('score', 0.0) for p in proposals]\n",
    "            telemetry.proposals_avg_score = sum(scores) / len(scores)\n",
    "            telemetry.proposals_kinds = [p.get('kind', 'unknown') for p in proposals]\n",
    "    \n",
    "    def record_decisions(self, telemetry: TickTelemetry, accepted: list, rejected: list):\n",
    "        \"\"\"Rejestruje decyzje w telemetrii\"\"\"\n",
    "        telemetry.accepted_count = len(accepted)\n",
    "        telemetry.rejected_count = len(rejected)\n",
    "        total = telemetry.accepted_count + telemetry.rejected_count\n",
    "        telemetry.acceptance_rate = telemetry.accepted_count / max(total, 1)\n",
    "    \n",
    "    def record_llm_call(self, telemetry: TickTelemetry, duration: float):\n",
    "        \"\"\"Rejestruje wywo≈Çanie LLM\"\"\"\n",
    "        telemetry.llm_calls += 1\n",
    "        telemetry.llm_total_time += duration\n",
    "        telemetry.llm_avg_time = telemetry.llm_total_time / telemetry.llm_calls\n",
    "    \n",
    "    def record_error(self, telemetry: TickTelemetry, error: Exception, context: str = \"\"):\n",
    "        \"\"\"Rejestruje b≈ÇƒÖd\"\"\"\n",
    "        telemetry.errors.append({\n",
    "            'type': type(error).__name__,\n",
    "            'message': str(error),\n",
    "            'context': context,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "        telemetry.error_count += 1\n",
    "    \n",
    "    def record_context_info(self, telemetry: TickTelemetry, context_chars: int, facts_used: int):\n",
    "        \"\"\"Rejestruje info o kontek≈õcie\"\"\"\n",
    "        telemetry.context_size_chars = context_chars\n",
    "        telemetry.memory_facts_used = facts_used\n",
    "    \n",
    "    def finish_tick_telemetry(self, telemetry: TickTelemetry) -> dict[str, Any]:\n",
    "        \"\"\"Ko≈Ñczy telemetriƒô tick-a i dodaje do batch\"\"\"\n",
    "        telemetry.total_duration = time.time() - telemetry.timestamp\n",
    "        \n",
    "        # Dodaj do batch\n",
    "        self.telemetry_batch.append(telemetry)\n",
    "        \n",
    "        # Zaktualizuj summary\n",
    "        self._update_metrics_summary(telemetry)\n",
    "        \n",
    "        # Flush batch je≈õli pe≈Çny\n",
    "        if len(self.telemetry_batch) >= self.batch_size:\n",
    "            self._flush_batch()\n",
    "        \n",
    "        return self._telemetry_to_dict(telemetry)\n",
    "    \n",
    "    def _update_metrics_summary(self, telemetry: TickTelemetry):\n",
    "        \"\"\"Aktualizuje rolling summary metryk\"\"\"\n",
    "        self.metrics_summary['proposals_count'].append(telemetry.proposals_count)\n",
    "        self.metrics_summary['acceptance_rate'].append(telemetry.acceptance_rate)\n",
    "        self.metrics_summary['llm_avg_time'].append(telemetry.llm_avg_time)\n",
    "        self.metrics_summary['total_duration'].append(telemetry.total_duration)\n",
    "        self.metrics_summary['error_count'].append(telemetry.error_count)\n",
    "        \n",
    "        # Ogranicz rozmiar rolling window\n",
    "        for key in self.metrics_summary:\n",
    "            if len(self.metrics_summary[key]) > 100:\n",
    "                self.metrics_summary[key] = self.metrics_summary[key][-100:]\n",
    "    \n",
    "    def _flush_batch(self):\n",
    "        \"\"\"Wysy≈Ça batch telemetrii do pamiƒôci\"\"\"\n",
    "        if not self.telemetry_batch:\n",
    "            return\n",
    "            \n",
    "        batch_summary = self._create_batch_summary()\n",
    "        \n",
    "        print(f\"üì§ Flush telemetrii: {len(self.telemetry_batch)} tick-√≥w\")\n",
    "        print(f\"   ≈örednia proposals: {batch_summary['avg_proposals']:.1f}\")\n",
    "        print(f\"   ≈örednia acceptance rate: {batch_summary['avg_acceptance_rate']:.2f}\")\n",
    "        print(f\"   ≈öredni czas LLM: {batch_summary['avg_llm_time']:.2f}s\")\n",
    "        \n",
    "        # Tu doda≈Çby≈õ zapis do memory z tagiem \"telemetry:batch\"\n",
    "        \n",
    "        self.telemetry_batch.clear()\n",
    "    \n",
    "    def _create_batch_summary(self) -> dict[str, Any]:\n",
    "        \"\"\"Tworzy podsumowanie batch-a\"\"\"\n",
    "        if not self.telemetry_batch:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'batch_size': len(self.telemetry_batch),\n",
    "            'timespan': self.telemetry_batch[-1].timestamp - self.telemetry_batch[0].timestamp,\n",
    "            'avg_proposals': sum(t.proposals_count for t in self.telemetry_batch) / len(self.telemetry_batch),\n",
    "            'avg_acceptance_rate': sum(t.acceptance_rate for t in self.telemetry_batch) / len(self.telemetry_batch),\n",
    "            'avg_llm_time': sum(t.llm_avg_time for t in self.telemetry_batch) / len(self.telemetry_batch),\n",
    "            'total_errors': sum(t.error_count for t in self.telemetry_batch),\n",
    "            'unique_kinds': len(set(kind for t in self.telemetry_batch for kind in t.proposals_kinds))\n",
    "        }\n",
    "    \n",
    "    def _telemetry_to_dict(self, telemetry: TickTelemetry) -> dict[str, Any]:\n",
    "        \"\"\"Konwertuje telemetriƒô do dict\"\"\"\n",
    "        return {\n",
    "            'tick_id': telemetry.tick_id,\n",
    "            'timestamp': telemetry.timestamp,\n",
    "            'proposals': {\n",
    "                'count': telemetry.proposals_count,\n",
    "                'avg_score': telemetry.proposals_avg_score,\n",
    "                'kinds': telemetry.proposals_kinds\n",
    "            },\n",
    "            'decisions': {\n",
    "                'accepted': telemetry.accepted_count,\n",
    "                'rejected': telemetry.rejected_count,\n",
    "                'acceptance_rate': telemetry.acceptance_rate\n",
    "            },\n",
    "            'performance': {\n",
    "                'llm_calls': telemetry.llm_calls,\n",
    "                'llm_total_time': telemetry.llm_total_time,\n",
    "                'llm_avg_time': telemetry.llm_avg_time,\n",
    "                'total_duration': telemetry.total_duration\n",
    "            },\n",
    "            'errors': telemetry.errors,\n",
    "            'context': {\n",
    "                'size_chars': telemetry.context_size_chars,\n",
    "                'facts_used': telemetry.memory_facts_used\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_rolling_metrics(self) -> dict[str, Any]:\n",
    "        \"\"\"Zwraca rolling metryki\"\"\"\n",
    "        if not self.metrics_summary:\n",
    "            return {}\n",
    "        \n",
    "        def safe_avg(values): \n",
    "            return sum(values) / len(values) if values else 0.0\n",
    "        \n",
    "        return {\n",
    "            'window_size': len(self.metrics_summary.get('proposals_count', [])),\n",
    "            'avg_proposals_per_tick': safe_avg(self.metrics_summary['proposals_count']),\n",
    "            'avg_acceptance_rate': safe_avg(self.metrics_summary['acceptance_rate']),\n",
    "            'avg_llm_time': safe_avg(self.metrics_summary['llm_avg_time']),\n",
    "            'avg_tick_duration': safe_avg(self.metrics_summary['total_duration']),\n",
    "            'error_rate': safe_avg(self.metrics_summary['error_count'])\n",
    "        }\n",
    "\n",
    "# Test systemu telemetrii\n",
    "print(\"üìä Test systemu telemetrii per tick:\")\n",
    "\n",
    "collector = TelemetryCollector(batch_size=3)\n",
    "\n",
    "# Symulacja tick-a 1\n",
    "telemetry1 = collector.start_tick_telemetry(\"tick_001\")\n",
    "\n",
    "# Symuluj propozycje\n",
    "proposals = [\n",
    "    {'kind': 'code_review', 'score': 0.8, 'title': 'Review auth'},\n",
    "    {'kind': 'documentation', 'score': 0.6, 'title': 'Update API docs'},\n",
    "    {'kind': 'testing', 'score': 0.7, 'title': 'Add unit tests'}\n",
    "]\n",
    "collector.record_proposals(telemetry1, proposals)\n",
    "\n",
    "# Symuluj decyzje\n",
    "accepted = [proposals[0], proposals[2]]  # 2 z 3 zaakceptowane\n",
    "rejected = [proposals[1]]\n",
    "collector.record_decisions(telemetry1, accepted, rejected)\n",
    "\n",
    "# Symuluj wywo≈Çania LLM\n",
    "collector.record_llm_call(telemetry1, 1.2)  # 1.2s\n",
    "collector.record_llm_call(telemetry1, 0.8)  # 0.8s\n",
    "\n",
    "# Symuluj b≈ÇƒÖd\n",
    "collector.record_error(telemetry1, ConnectionError(\"API timeout\"), \"LLM call\")\n",
    "\n",
    "# Symuluj kontekst\n",
    "collector.record_context_info(telemetry1, context_chars=4500, facts_used=12)\n",
    "\n",
    "# Zako≈Ñcz telemetriƒô\n",
    "result1 = collector.finish_tick_telemetry(telemetry1)\n",
    "\n",
    "print(\"üìà Telemetria tick_001:\")\n",
    "print(f\"   Proposals: {result1['proposals']['count']}, avg score: {result1['proposals']['avg_score']:.2f}\")\n",
    "print(f\"   Acceptance rate: {result1['decisions']['acceptance_rate']:.2f}\")\n",
    "print(f\"   LLM: {result1['performance']['llm_calls']} calls, avg {result1['performance']['llm_avg_time']:.2f}s\")\n",
    "print(f\"   Errors: {len(result1['errors'])}\")\n",
    "\n",
    "# Dodaj jeszcze 2 tick-i ≈ºeby wywo≈Çaƒá flush\n",
    "for i in range(2, 4):\n",
    "    tel = collector.start_tick_telemetry(f\"tick_00{i}\")\n",
    "    collector.record_proposals(tel, [{'kind': 'maintenance', 'score': 0.5}])\n",
    "    collector.record_decisions(tel, [], [])\n",
    "    collector.finish_tick_telemetry(tel)\n",
    "\n",
    "print(\"\\nüìä Rolling metrics:\", collector.get_rolling_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96ce2b",
   "metadata": {},
   "source": [
    "## üìà 6. KPI psychiki i metryki\n",
    "\n",
    "Rolling ≈õrednia reward, % trafnych akcji, drift wag i heatmapa kinds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7c63ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Test systemu KPI psychiki:\n",
      "üìä Performance:\n",
      "   Rolling reward avg: 0.700\n",
      "   Success rate: 0.800\n",
      "   Sample size: 15\n",
      "\n",
      "üìà Trends:\n",
      "   Reward trend: +0.107\n",
      "   Success trend: +0.161\n",
      "   Trending up: True\n",
      "\n",
      "üî• Top performing kinds:\n",
      "   code_review: 0.950\n",
      "   optimization: 0.950\n",
      "   testing: 0.905\n",
      "\n",
      "‚ùÑÔ∏è Weight drift:\n",
      "   exploration: 0.100\n",
      "   risk_aversion: 0.100\n",
      "   goal_weight: 0.050\n",
      "\n",
      "üó∫Ô∏è Kind heatmap:\n",
      "   code_review: 4 attempts, 1.00 success, 0.88 avg reward\n",
      "   documentation: 3 attempts, 0.67 success, 0.53 avg reward\n",
      "   testing: 4 attempts, 1.00 success, 0.76 avg reward\n",
      "   refactoring: 2 attempts, 0.00 success, 0.30 avg reward\n",
      "   optimization: 2 attempts, 1.00 success, 0.88 avg reward\n"
     ]
    }
   ],
   "source": [
    "class PsychikaKPI:\n",
    "    \"\"\"System KPI i metryk psychiki AI\"\"\"\n",
    "    \n",
    "    def __init__(self, window_size: int = 50):\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Rolling buffers\n",
    "        self.rewards = deque(maxlen=window_size)\n",
    "        self.action_success = deque(maxlen=window_size)  # bool success/failure\n",
    "        self.action_kinds = deque(maxlen=window_size)\n",
    "        \n",
    "        # Weight history dla drift detection\n",
    "        self.weight_history = []  # [(timestamp, weights_dict)]\n",
    "        self.max_weight_history = 100\n",
    "        \n",
    "        # Heat map data\n",
    "        self.kind_performance = defaultdict(lambda: {'attempts': 0, 'successes': 0, 'rewards': []})\n",
    "        \n",
    "    def record_action_outcome(self, action_kind: str, reward: float, success: bool):\n",
    "        \"\"\"Rejestruje wynik akcji\"\"\"\n",
    "        self.rewards.append(reward)\n",
    "        self.action_success.append(success)\n",
    "        self.action_kinds.append(action_kind)\n",
    "        \n",
    "        # Aktualizuj heat map\n",
    "        self.kind_performance[action_kind]['attempts'] += 1\n",
    "        if success:\n",
    "            self.kind_performance[action_kind]['successes'] += 1\n",
    "        self.kind_performance[action_kind]['rewards'].append(reward)\n",
    "        \n",
    "        # Ogranicz historiƒô nagr√≥d per kind\n",
    "        if len(self.kind_performance[action_kind]['rewards']) > 20:\n",
    "            self.kind_performance[action_kind]['rewards'] = \\\n",
    "                self.kind_performance[action_kind]['rewards'][-20:]\n",
    "    \n",
    "    def record_weights_snapshot(self, weights: dict[str, float]):\n",
    "        \"\"\"Zapisuje snapshot wag dla drift detection\"\"\"\n",
    "        self.weight_history.append((time.time(), weights.copy()))\n",
    "        \n",
    "        # Ogranicz historiƒô\n",
    "        if len(self.weight_history) > self.max_weight_history:\n",
    "            self.weight_history = self.weight_history[-self.max_weight_history:]\n",
    "    \n",
    "    def get_rolling_reward_avg(self) -> float:\n",
    "        \"\"\"Rolling ≈õrednia reward\"\"\"\n",
    "        return sum(self.rewards) / len(self.rewards) if self.rewards else 0.0\n",
    "    \n",
    "    def get_success_rate(self) -> float:\n",
    "        \"\"\"Procent trafnych akcji\"\"\"\n",
    "        if not self.action_success:\n",
    "            return 0.0\n",
    "        return sum(self.action_success) / len(self.action_success)\n",
    "    \n",
    "    def get_weight_drift(self, lookback_minutes: int = 60) -> dict[str, float]:\n",
    "        \"\"\"Oblicza drift wag w ostatnich N minutach\"\"\"\n",
    "        if len(self.weight_history) < 2:\n",
    "            return {}\n",
    "        \n",
    "        now = time.time()\n",
    "        cutoff_time = now - (lookback_minutes * 60)\n",
    "        \n",
    "        # Znajd≈∫ najstarszƒÖ i najnowszƒÖ wagƒô w oknie\n",
    "        recent_weights = [\n",
    "            (ts, weights) for ts, weights in self.weight_history \n",
    "            if ts >= cutoff_time\n",
    "        ]\n",
    "        \n",
    "        if len(recent_weights) < 2:\n",
    "            return {}\n",
    "        \n",
    "        oldest_weights = recent_weights[0][1]\n",
    "        newest_weights = recent_weights[-1][1]\n",
    "        \n",
    "        # Oblicz drift dla ka≈ºdej wagi\n",
    "        drift = {}\n",
    "        for key in newest_weights:\n",
    "            if key in oldest_weights:\n",
    "                drift[key] = abs(newest_weights[key] - oldest_weights[key])\n",
    "        \n",
    "        return drift\n",
    "    \n",
    "    def get_kind_heatmap(self) -> dict[str, dict[str, float]]:\n",
    "        \"\"\"Heatmapa performance per kind akcji\"\"\"\n",
    "        heatmap = {}\n",
    "        \n",
    "        for kind, data in self.kind_performance.items():\n",
    "            if data['attempts'] > 0:\n",
    "                success_rate = data['successes'] / data['attempts']\n",
    "                avg_reward = sum(data['rewards']) / len(data['rewards']) if data['rewards'] else 0.0\n",
    "                \n",
    "                heatmap[kind] = {\n",
    "                    'attempts': data['attempts'],\n",
    "                    'success_rate': success_rate,\n",
    "                    'avg_reward': avg_reward,\n",
    "                    'total_reward': sum(data['rewards']),\n",
    "                    'performance_score': (success_rate * 0.6) + (avg_reward * 0.4)  # Composite score\n",
    "                }\n",
    "        \n",
    "        return heatmap\n",
    "    \n",
    "    def get_trend_analysis(self) -> dict[str, Any]:\n",
    "        \"\"\"Analiza trend√≥w w ostatnich danych\"\"\"\n",
    "        if len(self.rewards) < 10:\n",
    "            return {'insufficient_data': True}\n",
    "        \n",
    "        # Podziel dane na pierwszƒÖ i drugƒÖ po≈Çowƒô\n",
    "        mid_point = len(self.rewards) // 2\n",
    "        first_half_rewards = list(self.rewards)[:mid_point]\n",
    "        second_half_rewards = list(self.rewards)[mid_point:]\n",
    "        \n",
    "        first_half_success = list(self.action_success)[:mid_point]\n",
    "        second_half_success = list(self.action_success)[mid_point:]\n",
    "        \n",
    "        # Oblicz trendy z zabezpieczeniem przed dzieleniem przez zero\n",
    "        def safe_avg(lst):\n",
    "            return sum(lst) / len(lst) if lst else 0.0\n",
    "\n",
    "        reward_trend = safe_avg(second_half_rewards) - safe_avg(first_half_rewards)\n",
    "        success_trend = safe_avg(second_half_success) - safe_avg(first_half_success)\n",
    "        \n",
    "        return {\n",
    "            'reward_trend': reward_trend,\n",
    "            'success_trend': success_trend,\n",
    "            'trending_up': reward_trend > 0.05 and success_trend > 0.05,\n",
    "            'trending_down': reward_trend < -0.05 or success_trend < -0.1,\n",
    "            'sample_size': len(self.rewards)\n",
    "        }\n",
    "    \n",
    "    def get_comprehensive_report(self) -> dict[str, Any]:\n",
    "        \"\"\"Kompletny raport KPI\"\"\"\n",
    "        return {\n",
    "            'performance': {\n",
    "                'rolling_reward_avg': self.get_rolling_reward_avg(),\n",
    "                'success_rate': self.get_success_rate(),\n",
    "                'sample_size': len(self.rewards)\n",
    "            },\n",
    "            'weight_drift': self.get_weight_drift(),\n",
    "            'kind_heatmap': self.get_kind_heatmap(),\n",
    "            'trends': self.get_trend_analysis(),\n",
    "            'top_performing_kinds': self._get_top_kinds_by_performance(),\n",
    "            'bottom_performing_kinds': self._get_bottom_kinds_by_performance()\n",
    "        }\n",
    "    \n",
    "    def _get_top_kinds_by_performance(self, limit: int = 3) -> list[tuple[str, float]]:\n",
    "        \"\"\"Top performing action kinds\"\"\"\n",
    "        heatmap = self.get_kind_heatmap()\n",
    "        sorted_kinds = sorted(\n",
    "            heatmap.items(), \n",
    "            key=lambda x: x[1]['performance_score'], \n",
    "            reverse=True\n",
    "        )\n",
    "        return [(kind, data['performance_score']) for kind, data in sorted_kinds[:limit]]\n",
    "    \n",
    "    def _get_bottom_kinds_by_performance(self, limit: int = 3) -> list[tuple[str, float]]:\n",
    "        \"\"\"Worst performing action kinds\"\"\"\n",
    "        heatmap = self.get_kind_heatmap()\n",
    "        sorted_kinds = sorted(\n",
    "            heatmap.items(), \n",
    "            key=lambda x: x[1]['performance_score']\n",
    "        )\n",
    "        return [(kind, data['performance_score']) for kind, data in sorted_kinds[:limit]]\n",
    "\n",
    "# Test systemu KPI psychiki\n",
    "print(\"üìà Test systemu KPI psychiki:\")\n",
    "\n",
    "kpi = PsychikaKPI(window_size=20)\n",
    "\n",
    "# Symuluj dzia≈Çania systemu\n",
    "actions_simulation = [\n",
    "    ('code_review', 0.8, True),\n",
    "    ('documentation', 0.6, True),\n",
    "    ('testing', 0.7, True),\n",
    "    ('code_review', 0.9, True),\n",
    "    ('refactoring', 0.4, False),\n",
    "    ('documentation', 0.3, False),\n",
    "    ('testing', 0.8, True),\n",
    "    ('code_review', 0.85, True),\n",
    "    ('optimization', 0.9, True),\n",
    "    ('testing', 0.75, True),\n",
    "    ('refactoring', 0.2, False),\n",
    "    ('code_review', 0.95, True),\n",
    "    ('documentation', 0.7, True),\n",
    "    ('optimization', 0.85, True),\n",
    "    ('testing', 0.8, True),\n",
    "]\n",
    "\n",
    "# Zapisz snapshot wag na poczƒÖtku\n",
    "initial_weights = {'exploration': 0.3, 'risk_aversion': 0.4, 'goal_weight': 0.8}\n",
    "kpi.record_weights_snapshot(initial_weights)\n",
    "\n",
    "# Symuluj akcje\n",
    "for kind, reward, success in actions_simulation:\n",
    "    kpi.record_action_outcome(kind, reward, success)\n",
    "    time.sleep(0.01)  # Ma≈Çe op√≥≈∫nienie dla r√≥≈ºnych timestamp√≥w\n",
    "\n",
    "# Symuluj zmianƒô wag\n",
    "time.sleep(0.1)\n",
    "changed_weights = {'exploration': 0.4, 'risk_aversion': 0.3, 'goal_weight': 0.85}\n",
    "kpi.record_weights_snapshot(changed_weights)\n",
    "\n",
    "# Generuj raport\n",
    "report = kpi.get_comprehensive_report()\n",
    "\n",
    "print(\"üìä Performance:\")\n",
    "print(f\"   Rolling reward avg: {report['performance']['rolling_reward_avg']:.3f}\")\n",
    "print(f\"   Success rate: {report['performance']['success_rate']:.3f}\")\n",
    "print(f\"   Sample size: {report['performance']['sample_size']}\")\n",
    "\n",
    "print(\"\\nüìà Trends:\")\n",
    "trends = report['trends']\n",
    "if not trends.get('insufficient_data'):\n",
    "    print(f\"   Reward trend: {trends['reward_trend']:+.3f}\")\n",
    "    print(f\"   Success trend: {trends['success_trend']:+.3f}\")\n",
    "    print(f\"   Trending up: {trends['trending_up']}\")\n",
    "\n",
    "print(\"\\nüî• Top performing kinds:\")\n",
    "for kind, score in report['top_performing_kinds']:\n",
    "    print(f\"   {kind}: {score:.3f}\")\n",
    "\n",
    "print(\"\\n‚ùÑÔ∏è Weight drift:\")\n",
    "for weight, drift in report['weight_drift'].items():\n",
    "    print(f\"   {weight}: {drift:.3f}\")\n",
    "\n",
    "print(\"\\nüó∫Ô∏è Kind heatmap:\")\n",
    "for kind, data in report['kind_heatmap'].items():\n",
    "    print(f\"   {kind}: {data['attempts']} attempts, {data['success_rate']:.2f} success, {data['avg_reward']:.2f} avg reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530707c",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 7. Presety i tryby pracy\n",
    "\n",
    "Implementacja tryb√≥w raid/grinder/monk i auto-preset z warunkami prze≈ÇƒÖczania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce60297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Test systemu preset√≥w i tryb√≥w pracy:\n",
      "üìã Aktualny preset: balanced\n",
      "üîÑ Prze≈ÇƒÖczono na preset 'raid': Szybkie, efektywne akcje z wysokƒÖ eksploracjƒÖ\n",
      "üöÄ Raid preset - exploration: 0.8, risk_aversion: 0.2\n",
      "\n",
      "ü§ñ Test logiki auto-preset:\n",
      "   Wysokie zmƒôczenie ‚Üí monk\n",
      "   ≈öwietna forma ‚Üí creative_max\n",
      "   S≈Çaba performance ‚Üí grinder\n",
      "\n",
      "üéØ Test filtrowania akcji dla preset 'raid':\n",
      "   Przed filtrowaniem: 4 akcji\n",
      "   Po filtrowaniu: 2 akcji\n",
      "     ‚úÖ quick_fix (effort: 0.3) +boost\n",
      "     ‚úÖ micro_break (effort: 0.1) \n",
      "\n",
      "üìä Status preset√≥w: {'current_preset': 'raid', 'auto_enabled': True, 'manual_override_until': 0, 'manual_override_active': False, 'available_presets': ['raid', 'grinder', 'monk', 'creative_max', 'balanced'], 'recent_changes': [{'timestamp': 1758051564.1302881, 'from': 'balanced', 'to': 'raid', 'manual': True, 'duration_minutes': 0}], 'current_config': {'exploration': 0.8, 'risk_aversion': 0.2, 'effort_limit': 0.6}}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class PresetConfig:\n",
    "    \"\"\"Konfiguracja presetu pracy\"\"\"\n",
    "    name: str\n",
    "    exploration: float\n",
    "    risk_aversion: float\n",
    "    goal_weight: float\n",
    "    effort_limit: float\n",
    "    bandit_weight: float\n",
    "    preferred_kinds: list[str]\n",
    "    blocked_kinds: list[str]\n",
    "    description: str\n",
    "\n",
    "class PresetManager:\n",
    "    \"\"\"Manager preset√≥w i tryb√≥w pracy\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.presets = self._initialize_presets()\n",
    "        self.current_preset = \"balanced\"\n",
    "        self.auto_preset_enabled = True\n",
    "        self.preset_change_history = []\n",
    "        self.manual_override_until = 0  # timestamp\n",
    "        \n",
    "    def _initialize_presets(self) -> dict[str, PresetConfig]:\n",
    "        \"\"\"Inicjalizuje domy≈õlne presety\"\"\"\n",
    "        return {\n",
    "            \"raid\": PresetConfig(\n",
    "                name=\"raid\",\n",
    "                exploration=0.8,\n",
    "                risk_aversion=0.2,\n",
    "                goal_weight=0.9,\n",
    "                effort_limit=0.6,\n",
    "                bandit_weight=0.3,\n",
    "                preferred_kinds=[\"quick_fix\", \"optimization\", \"code_review\"],\n",
    "                blocked_kinds=[\"long_research\", \"documentation\"],\n",
    "                description=\"Szybkie, efektywne akcje z wysokƒÖ eksploracjƒÖ\"\n",
    "            ),\n",
    "            \"grinder\": PresetConfig(\n",
    "                name=\"grinder\",\n",
    "                exploration=0.2,\n",
    "                risk_aversion=0.4,\n",
    "                goal_weight=0.95,\n",
    "                effort_limit=1.0,\n",
    "                bandit_weight=0.7,\n",
    "                preferred_kinds=[\"maintenance\", \"testing\", \"documentation\", \"memory_compact\"],\n",
    "                blocked_kinds=[],\n",
    "                description=\"Systematyczne dzia≈Çania utrzymaniowe i rozwojowe\"\n",
    "            ),\n",
    "            \"monk\": PresetConfig(\n",
    "                name=\"monk\",\n",
    "                exploration=0.1,\n",
    "                risk_aversion=0.8,\n",
    "                goal_weight=0.4,\n",
    "                effort_limit=0.4,\n",
    "                bandit_weight=0.1,\n",
    "                preferred_kinds=[\"micro_break\", \"health_check\", \"reflection\"],\n",
    "                blocked_kinds=[\"high_effort\", \"complex_task\"],\n",
    "                description=\"Tryb regeneracji i niskiego wysi≈Çku\"\n",
    "            ),\n",
    "            \"creative_max\": PresetConfig(\n",
    "                name=\"creative_max\",\n",
    "                exploration=0.95,\n",
    "                risk_aversion=0.1,\n",
    "                goal_weight=0.6,\n",
    "                effort_limit=0.8,\n",
    "                bandit_weight=0.2,\n",
    "                preferred_kinds=[\"brainstorm\", \"prototype\", \"experiment\"],\n",
    "                blocked_kinds=[\"routine\"],\n",
    "                description=\"Maksymalna kreatywno≈õƒá i eksploracja\"\n",
    "            ),\n",
    "            \"balanced\": PresetConfig(\n",
    "                name=\"balanced\",\n",
    "                exploration=0.5,\n",
    "                risk_aversion=0.5,\n",
    "                goal_weight=0.7,\n",
    "                effort_limit=0.7,\n",
    "                bandit_weight=0.5,\n",
    "                preferred_kinds=[],\n",
    "                blocked_kinds=[],\n",
    "                description=\"Zr√≥wnowa≈ºony tryb pracy\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def get_current_preset(self) -> PresetConfig:\n",
    "        \"\"\"Zwraca aktualny preset\"\"\"\n",
    "        return self.presets[self.current_preset]\n",
    "    \n",
    "    def switch_preset(self, preset_name: str, duration_minutes: int = 0, manual: bool = False) -> bool:\n",
    "        \"\"\"Prze≈ÇƒÖcza na inny preset\"\"\"\n",
    "        if preset_name not in self.presets:\n",
    "            print(f\"‚ùå Nieznany preset: {preset_name}\")\n",
    "            return False\n",
    "        \n",
    "        old_preset = self.current_preset\n",
    "        self.current_preset = preset_name\n",
    "        \n",
    "        # Historia zmian\n",
    "        self.preset_change_history.append({\n",
    "            'timestamp': time.time(),\n",
    "            'from': old_preset,\n",
    "            'to': preset_name,\n",
    "            'manual': manual,\n",
    "            'duration_minutes': duration_minutes\n",
    "        })\n",
    "        \n",
    "        # Je≈õli manual override z czasem\n",
    "        if manual and duration_minutes > 0:\n",
    "            self.manual_override_until = time.time() + (duration_minutes * 60)\n",
    "        \n",
    "        preset_config = self.presets[preset_name]\n",
    "        print(f\"üîÑ Prze≈ÇƒÖczono na preset '{preset_name}': {preset_config.description}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def check_auto_preset_conditions(self, fatigue: float, stress: float, mood: float, \n",
    "                                   time_of_day: int, recent_performance: float) -> str | None:\n",
    "        \"\"\"Sprawdza warunki auto-preset i zwraca sugerowany preset\"\"\"\n",
    "        \n",
    "        if not self.auto_preset_enabled:\n",
    "            return None\n",
    "            \n",
    "        # Sprawd≈∫ manual override\n",
    "        if time.time() < self.manual_override_until:\n",
    "            return None\n",
    "        \n",
    "        # Warunki prze≈ÇƒÖczania\n",
    "        \n",
    "        # Wysokie zmƒôczenie ‚Üí monk\n",
    "        if fatigue > 0.7 or stress > 0.8:\n",
    "            return \"monk\"\n",
    "        \n",
    "        # Bardzo niskie zmƒôczenie + dobry nastr√≥j ‚Üí creative lub raid\n",
    "        if fatigue < 0.3 and mood > 0.7:\n",
    "            if recent_performance > 0.8:\n",
    "                return \"creative_max\"\n",
    "            else:\n",
    "                return \"raid\"\n",
    "        \n",
    "        # S≈Çaba performance ‚Üí grinder (systematyczna praca)\n",
    "        if recent_performance < 0.4:\n",
    "            return \"grinder\"\n",
    "        \n",
    "        # Godziny wieczorne ‚Üí monk\n",
    "        if time_of_day >= 22 or time_of_day <= 6:\n",
    "            return \"monk\"\n",
    "        \n",
    "        # Godziny robocze + dobra forma ‚Üí raid lub balanced\n",
    "        if 9 <= time_of_day <= 17 and fatigue < 0.5:\n",
    "            return \"raid\" if mood > 0.6 else \"balanced\"\n",
    "        \n",
    "        # Domy≈õlnie balanced\n",
    "        return \"balanced\"\n",
    "    \n",
    "    def apply_preset_to_weights(self, weights: dict[str, float]) -> dict[str, float]:\n",
    "        \"\"\"Aplikuje aktualny preset do wag\"\"\"\n",
    "        preset = self.get_current_preset()\n",
    "        \n",
    "        # Skopiuj istniejƒÖce wagi\n",
    "        new_weights = weights.copy()\n",
    "        \n",
    "        # Zastosuj wagi z presetu\n",
    "        new_weights.update({\n",
    "            'exploration': preset.exploration,\n",
    "            'risk_aversion': preset.risk_aversion,\n",
    "            'goal_weight': preset.goal_weight,\n",
    "            'bandit': preset.bandit_weight\n",
    "        })\n",
    "        \n",
    "        return new_weights\n",
    "    \n",
    "    def filter_actions_by_preset(self, actions: list[dict]) -> list[dict]:\n",
    "        \"\"\"Filtruje akcje wed≈Çug aktualnego presetu\"\"\"\n",
    "        preset = self.get_current_preset()\n",
    "        filtered = []\n",
    "        \n",
    "        for action in actions:\n",
    "            kind = action.get('kind', '')\n",
    "            effort = action.get('effort', 0.5)\n",
    "            \n",
    "            # Sprawd≈∫ blocked kinds\n",
    "            if any(blocked in kind.lower() for blocked in preset.blocked_kinds):\n",
    "                continue\n",
    "                \n",
    "            # Sprawd≈∫ effort limit\n",
    "            if effort > preset.effort_limit:\n",
    "                continue\n",
    "            \n",
    "            # Boost dla preferred kinds\n",
    "            if any(preferred in kind.lower() for preferred in preset.preferred_kinds):\n",
    "                action = action.copy()\n",
    "                action['preset_boost'] = 0.2\n",
    "            \n",
    "            filtered.append(action)\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    def get_preset_status(self) -> dict[str, Any]:\n",
    "        \"\"\"Zwraca status systemu preset√≥w\"\"\"\n",
    "        return {\n",
    "            'current_preset': self.current_preset,\n",
    "            'auto_enabled': self.auto_preset_enabled,\n",
    "            'manual_override_until': self.manual_override_until,\n",
    "            'manual_override_active': time.time() < self.manual_override_until,\n",
    "            'available_presets': list(self.presets.keys()),\n",
    "            'recent_changes': self.preset_change_history[-5:] if self.preset_change_history else [],\n",
    "            'current_config': {\n",
    "                'exploration': self.get_current_preset().exploration,\n",
    "                'risk_aversion': self.get_current_preset().risk_aversion,\n",
    "                'effort_limit': self.get_current_preset().effort_limit\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Test systemu preset√≥w\n",
    "print(\"‚öôÔ∏è Test systemu preset√≥w i tryb√≥w pracy:\")\n",
    "\n",
    "preset_manager = PresetManager()\n",
    "\n",
    "# Test prze≈ÇƒÖczania preset√≥w\n",
    "print(f\"üìã Aktualny preset: {preset_manager.current_preset}\")\n",
    "\n",
    "# Prze≈ÇƒÖcz na raid\n",
    "preset_manager.switch_preset(\"raid\", manual=True)\n",
    "raid_preset = preset_manager.get_current_preset()\n",
    "print(f\"üöÄ Raid preset - exploration: {raid_preset.exploration}, risk_aversion: {raid_preset.risk_aversion}\")\n",
    "\n",
    "# Test auto-preset logic\n",
    "print(\"\\nü§ñ Test logiki auto-preset:\")\n",
    "\n",
    "# Scenariusz 1: Wysokie zmƒôczenie\n",
    "suggested = preset_manager.check_auto_preset_conditions(\n",
    "    fatigue=0.8, stress=0.6, mood=0.4, time_of_day=14, recent_performance=0.6\n",
    ")\n",
    "print(f\"   Wysokie zmƒôczenie ‚Üí {suggested}\")\n",
    "\n",
    "# Scenariusz 2: ≈öwietna forma\n",
    "suggested = preset_manager.check_auto_preset_conditions(\n",
    "    fatigue=0.2, stress=0.1, mood=0.9, time_of_day=10, recent_performance=0.9\n",
    ")\n",
    "print(f\"   ≈öwietna forma ‚Üí {suggested}\")\n",
    "\n",
    "# Scenariusz 3: S≈Çaba performance\n",
    "suggested = preset_manager.check_auto_preset_conditions(\n",
    "    fatigue=0.4, stress=0.3, mood=0.5, time_of_day=15, recent_performance=0.3\n",
    ")\n",
    "print(f\"   S≈Çaba performance ‚Üí {suggested}\")\n",
    "\n",
    "# Test filtrowania akcji\n",
    "test_actions = [\n",
    "    {'kind': 'quick_fix', 'effort': 0.3, 'title': 'Fix bug'},\n",
    "    {'kind': 'long_research', 'effort': 0.8, 'title': 'Deep analysis'},\n",
    "    {'kind': 'documentation', 'effort': 0.7, 'title': 'Write docs'},\n",
    "    {'kind': 'micro_break', 'effort': 0.1, 'title': 'Take break'}\n",
    "]\n",
    "\n",
    "print(f\"\\nüéØ Test filtrowania akcji dla preset '{raid_preset.name}':\")\n",
    "print(f\"   Przed filtrowaniem: {len(test_actions)} akcji\")\n",
    "filtered = preset_manager.filter_actions_by_preset(test_actions)\n",
    "print(f\"   Po filtrowaniu: {len(filtered)} akcji\")\n",
    "for action in filtered:\n",
    "    boost = action.get('preset_boost', 0)\n",
    "    print(f\"     ‚úÖ {action['kind']} (effort: {action['effort']}) {'+boost' if boost else ''}\")\n",
    "\n",
    "# Status systemu\n",
    "print(\"\\nüìä Status preset√≥w:\", preset_manager.get_preset_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544e5a6",
   "metadata": {},
   "source": [
    "## üíæ 8. Rozszerzenie STM do 10k znak√≥w i 100 wers√≥w\n",
    "\n",
    "Podniesienie limit√≥w STM z systemem ring buffer, snapshots i autokompresji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c459b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Test rozszerzonej STM (10k znak√≥w, 100 wers√≥w):\n",
      "üìù Dodajƒô 16 wiadomo≈õci...\n",
      "   üìä 5 msg, 158 chars (15.8%)\n",
      "   üìä 10 msg, 311 chars (31.1%)\n",
      "üóúÔ∏è Skompresowano 0 wiadomo≈õci, zachowano 1 salient\n",
      "üóúÔ∏è Skompresowano 2 wiadomo≈õci, zachowano 0 salient\n",
      "üóúÔ∏è Skompresowano 2 wiadomo≈õci, zachowano 0 salient\n",
      "üóúÔ∏è Skompresowano 1 wiadomo≈õci, zachowano 1 salient\n",
      "üóúÔ∏è Skompresowano 3 wiadomo≈õci, zachowano 0 salient\n",
      "üóúÔ∏è Skompresowano 2 wiadomo≈õci, zachowano 0 salient\n",
      "\\nüìä Finalne statystyki STM:\n",
      "   Wiadomo≈õci: 11 / 10\n",
      "   Znaki: 369 / 1000 (36.9%)\n",
      "   Salient: 3\n",
      "   Kompresje: 5\n",
      "   Snapshoty: 0\n",
      "\\nüì§ Kontekst dla LLM (480 znak√≥w):\n",
      "System: [COMPRESSED] Assistant: Testy przechodzƒÖ, coverage 85% | (2 wiadomo≈õci w -0.0 min)\\nUser: Refaktoryzacja modu≈Çu auth\\nAssistant: Refaktoryzacja uko≈Ñczona, kod czytelniejszy\\nUser: Deploy na staging\\nüî•User: Rozpoczynamy projekt X\\nAssistant: Deployment sukces, aplikacja dzia≈Ça\\nUser: Performa...\n"
     ]
    }
   ],
   "source": [
    "@dataclass \n",
    "class STMMessage:\n",
    "    \"\"\"Pojedyncza wiadomo≈õƒá w STM\"\"\"\n",
    "    content: str\n",
    "    timestamp: float\n",
    "    role: str  # 'user', 'assistant', 'system'\n",
    "    tags: list[str] = field(default_factory=list)\n",
    "    priority: str = \"normal\"  # 'high', 'normal', 'low'\n",
    "    salient: bool = False  # Czy zawiera wa≈ºne definicje/decyzje\n",
    "    char_count: int = 0\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.char_count = len(self.content)\n",
    "\n",
    "class ExtendedSTM:\n",
    "    \"\"\"Rozszerzona pamiƒôƒá kr√≥tkoterminowa 10k znak√≥w, 100 wers√≥w\"\"\"\n",
    "    \n",
    "    def __init__(self, char_limit: int = None, line_limit: int = None):\n",
    "        self.char_limit = CONFIG.STM_CHAR_LIMIT if char_limit is None else char_limit\n",
    "        self.line_limit = CONFIG.STM_LINE_LIMIT if line_limit is None else line_limit\n",
    "        self.summary_interval = CONFIG.STM_SUMMARY_INTERVAL\n",
    "        self.compression_ratio = CONFIG.STM_COMPRESSION_RATIO\n",
    "        \n",
    "        # Ring buffer dla wiadomo≈õci\n",
    "        self.messages = deque(maxlen=self.line_limit * 2)  # 2x buffer przed forceful cleanup\n",
    "        self.snapshots = []  # Snapshoty skompresowanych segment√≥w\n",
    "        self.total_chars = 0\n",
    "        self.snapshot_counter = 0\n",
    "        \n",
    "        # Metryki\n",
    "        self.compressions_performed = 0\n",
    "        self.messages_compressed = 0\n",
    "        \n",
    "    def add_message(self, content: str, role: str = \"user\", tags: list[str] = None, \n",
    "                   priority: str = \"normal\", salient: bool = False) -> None:\n",
    "        \"\"\"Dodaje wiadomo≈õƒá do STM\"\"\"\n",
    "        \n",
    "        message = STMMessage(\n",
    "            content=content,\n",
    "            timestamp=time.time(),\n",
    "            role=role,\n",
    "            tags=tags or [],\n",
    "            priority=priority,\n",
    "            salient=salient\n",
    "        )\n",
    "        \n",
    "        self.messages.append(message)\n",
    "        self.total_chars += message.char_count\n",
    "        \n",
    "        # Sprawd≈∫ czy potrzeba kompresji\n",
    "        self._check_and_compress()\n",
    "        \n",
    "        # Snapshot co N wiadomo≈õci\n",
    "        if len(self.messages) % self.summary_interval == 0:\n",
    "            self._create_snapshot()\n",
    "    \n",
    "    def _check_and_compress(self):\n",
    "        \"\"\"Sprawdza limity i kompresuje je≈õli potrzeba\"\"\"\n",
    "        \n",
    "        # Sprawd≈∫ limit znak√≥w\n",
    "        if self.total_chars > self.char_limit:\n",
    "            self._compress_oldest_messages()\n",
    "        \n",
    "        # Sprawd≈∫ limit wiadomo≈õci\n",
    "        if len(self.messages) > self.line_limit:\n",
    "            excess = len(self.messages) - self.line_limit\n",
    "            self._compress_oldest_messages(min_messages=excess)\n",
    "    \n",
    "    def _compress_oldest_messages(self, min_messages: int = None):\n",
    "        \"\"\"Kompresuje najstarsze wiadomo≈õci\"\"\"\n",
    "        \n",
    "        if len(self.messages) < 5:  # Minimum 5 wiadomo≈õci ≈ºeby kompresowaƒá\n",
    "            return\n",
    "        \n",
    "        # Ile wiadomo≈õci skompresowaƒá\n",
    "        if min_messages:\n",
    "            compress_count = min_messages\n",
    "        else:\n",
    "            # Kompresuj 25% najstarszych\n",
    "            compress_count = max(5, len(self.messages) // 4)\n",
    "        \n",
    "        # Nie kompresuj wiadomo≈õci salient - przenie≈õ na koniec\n",
    "        messages_to_compress = []\n",
    "        salient_messages = []\n",
    "        \n",
    "        for i in range(min(compress_count, len(self.messages))):\n",
    "            msg = self.messages.popleft()\n",
    "            self.total_chars -= msg.char_count\n",
    "            \n",
    "            if msg.salient or msg.priority == \"high\":\n",
    "                salient_messages.append(msg)\n",
    "            else:\n",
    "                messages_to_compress.append(msg)\n",
    "        \n",
    "        # Kompresja\n",
    "        if messages_to_compress:\n",
    "            compressed_summary = self._compress_messages(messages_to_compress)\n",
    "            \n",
    "            # Dodaj skompresowane podsumowanie jako nowƒÖ wiadomo≈õƒá\n",
    "            summary_msg = STMMessage(\n",
    "                content=f\"[COMPRESSED] {compressed_summary}\",\n",
    "                timestamp=time.time(),\n",
    "                role=\"system\",\n",
    "                tags=[\"compressed\", \"summary\"],\n",
    "                priority=\"normal\",\n",
    "                salient=False\n",
    "            )\n",
    "            \n",
    "            self.messages.appendleft(summary_msg)\n",
    "            self.total_chars += summary_msg.char_count\n",
    "            \n",
    "            self.compressions_performed += 1\n",
    "            self.messages_compressed += len(messages_to_compress)\n",
    "        \n",
    "        # Przywr√≥ƒá salient messages\n",
    "        for msg in salient_messages:\n",
    "            self.messages.append(msg)\n",
    "            self.total_chars += msg.char_count\n",
    "        \n",
    "        print(f\"üóúÔ∏è Skompresowano {len(messages_to_compress)} wiadomo≈õci, zachowano {len(salient_messages)} salient\")\n",
    "    \n",
    "    def _compress_messages(self, messages: list[STMMessage]) -> str:\n",
    "        \"\"\"Kompresuje listƒô wiadomo≈õci do podsumowania\"\"\"\n",
    "        \n",
    "        if not messages:\n",
    "            return \"Brak wiadomo≈õci do kompresji\"\n",
    "        \n",
    "        # Prosty algorytm kompresji - zachowaj kluczowe info\n",
    "        content_parts = []\n",
    "        timespan = messages[-1].timestamp - messages[0].timestamp\n",
    "        \n",
    "        # Grupuj wed≈Çug r√≥l\n",
    "        user_messages = [m.content for m in messages if m.role == \"user\"]\n",
    "        assistant_messages = [m.content for m in messages if m.role == \"assistant\"]\n",
    "        \n",
    "        summary_parts = []\n",
    "        \n",
    "        if user_messages:\n",
    "            # WyciƒÖgnij kluczowe s≈Çowa z user messages\n",
    "            key_topics = self._extract_key_topics(user_messages)\n",
    "            summary_parts.append(f\"User: {', '.join(key_topics[:5])}\")  # Top 5 topics\n",
    "        \n",
    "        if assistant_messages:\n",
    "            # Zachowaj ostatniƒÖ odpowied≈∫ asystenta (czƒô≈õciowo)\n",
    "            last_response = assistant_messages[-1]\n",
    "            if len(last_response) > 100:\n",
    "                last_response = last_response[:100] + \"...\"\n",
    "            summary_parts.append(f\"Assistant: {last_response}\")\n",
    "        \n",
    "        # Dodaj info o czasie\n",
    "        summary_parts.append(f\"({len(messages)} wiadomo≈õci w {timespan/60:.1f} min)\")\n",
    "        \n",
    "        return \" | \".join(summary_parts)\n",
    "    \n",
    "    def _extract_key_topics(self, messages: list[str]) -> list[str]:\n",
    "        \"\"\"WyciƒÖga kluczowe tematy z wiadomo≈õci\"\"\"\n",
    "        \n",
    "        # ≈ÅƒÖczy wszystkie wiadomo≈õci\n",
    "        combined = \" \".join(messages).lower()\n",
    "        \n",
    "        # Prosty algorytm wyciƒÖgania s≈Ç√≥w kluczowych\n",
    "        # Usu≈Ñ czƒôste s≈Çowa\n",
    "        stop_words = {'i', 'a', 'the', 'to', 'and', 'or', 'in', 'on', 'at', 'by', 'for', 'with', 'from'}\n",
    "        \n",
    "        words = re.findall(r'\\\\b\\\\w{3,}\\\\b', combined)  # S≈Çowa 3+ litery\n",
    "        word_counts = defaultdict(int)\n",
    "        \n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                word_counts[word] += 1\n",
    "        \n",
    "        # Zwr√≥ƒá najczƒôstsze s≈Çowa\n",
    "        return [word for word, count in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)]\n",
    "    \n",
    "    def _create_snapshot(self):\n",
    "        \"\"\"Tworzy snapshot aktualnego stanu STM\"\"\"\n",
    "        \n",
    "        self.snapshot_counter += 1\n",
    "        \n",
    "        snapshot = {\n",
    "            'id': self.snapshot_counter,\n",
    "            'timestamp': time.time(),\n",
    "            'message_count': len(self.messages),\n",
    "            'total_chars': self.total_chars,\n",
    "            'recent_topics': self._extract_key_topics([m.content for m in list(self.messages)[-10:]]),\n",
    "            'salient_count': sum(1 for m in self.messages if m.salient)\n",
    "        }\n",
    "        \n",
    "        self.snapshots.append(snapshot)\n",
    "        \n",
    "        # Ogranicz liczbƒô snapshots\n",
    "        if len(self.snapshots) > 20:\n",
    "            self.snapshots = self.snapshots[-20:]\n",
    "        \n",
    "        print(f\"üì∏ Snapshot #{self.snapshot_counter}: {snapshot['message_count']} wiadomo≈õci, {snapshot['total_chars']} znak√≥w\")\n",
    "    \n",
    "    def get_context_for_llm(self, max_chars: int = None, prioritize_recent: bool = True) -> str:\n",
    "        \"\"\"Zwraca kontekst dla LLM z priorytetyzacjƒÖ\"\"\"\n",
    "        \n",
    "        max_chars = max_chars or (self.char_limit // 2)  # Po≈Çowa limitu na kontekst\n",
    "        \n",
    "        if prioritize_recent:\n",
    "            # Zacznij od najnowszych wiadomo≈õci\n",
    "            selected_messages = []\n",
    "            char_count = 0\n",
    "            \n",
    "            for message in reversed(self.messages):\n",
    "                if char_count + message.char_count <= max_chars:\n",
    "                    selected_messages.insert(0, message)\n",
    "                    char_count += message.char_count\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # Zawsze uwzglƒôdnij salient messages\n",
    "            for message in self.messages:\n",
    "                if message.salient and message not in selected_messages:\n",
    "                    if char_count + message.char_count <= max_chars * 1.2:  # 20% buffer dla salient\n",
    "                        selected_messages.append(message)\n",
    "                        char_count += message.char_count\n",
    "        \n",
    "        else:\n",
    "            # R√≥wnomierne pr√≥bkowanie\n",
    "            selected_messages = list(self.messages)\n",
    "        \n",
    "        # Formatuj do tekstu\n",
    "        context_parts = []\n",
    "        for msg in selected_messages:\n",
    "            prefix = \"üî•\" if msg.salient else \"\"\n",
    "            context_parts.append(f\"{prefix}{msg.role.title()}: {msg.content}\")\n",
    "        \n",
    "        return \"\\\\n\".join(context_parts)\n",
    "    \n",
    "    def get_stats(self) -> dict[str, Any]:\n",
    "        \"\"\"Zwraca statystyki STM\"\"\"\n",
    "        \n",
    "        return {\n",
    "            'message_count': len(self.messages),\n",
    "            'total_chars': self.total_chars,\n",
    "            'char_utilization': self.total_chars / self.char_limit,\n",
    "            'line_utilization': len(self.messages) / self.line_limit,\n",
    "            'salient_messages': sum(1 for m in self.messages if m.salient),\n",
    "            'compressions_performed': self.compressions_performed,\n",
    "            'messages_compressed': self.messages_compressed,\n",
    "            'snapshots_created': len(self.snapshots),\n",
    "            'avg_message_length': self.total_chars / max(len(self.messages), 1),\n",
    "            'oldest_message_age': time.time() - self.messages[0].timestamp if self.messages else 0\n",
    "        }\n",
    "\n",
    "# Test rozszerzonej STM\n",
    "print(\"üíæ Test rozszerzonej STM (10k znak√≥w, 100 wers√≥w):\")\n",
    "\n",
    "stm = ExtendedSTM(char_limit=1000, line_limit=10)  # Ni≈ºsze limity dla testu\n",
    "\n",
    "# Dodaj seriƒô wiadomo≈õci\n",
    "messages_to_add = [\n",
    "    (\"Rozpoczynamy projekt X\", \"user\", [\"project\"], \"high\", True),\n",
    "    (\"Zrozumia≈Çem. Projekt X to system zarzƒÖdzania danymi.\", \"assistant\", [\"response\"]),\n",
    "    (\"Potrzebujemy implementacji API\", \"user\", [\"api\", \"implementation\"]),\n",
    "    (\"Zaczynam od endpoint√≥w RESTowych\", \"assistant\", [\"api\", \"rest\"]),\n",
    "    (\"Dodaj te≈º dokumentacjƒô\", \"user\", [\"documentation\"], \"normal\", True),\n",
    "    (\"Dokumentacja bƒôdzie w OpenAPI\", \"assistant\", [\"docs\", \"openapi\"]),\n",
    "    (\"Sprawd≈∫ testy jednostkowe\", \"user\", [\"testing\"]),\n",
    "    (\"Testy przechodzƒÖ, coverage 85%\", \"assistant\", [\"testing\", \"coverage\"]),\n",
    "    (\"Refaktoryzacja modu≈Çu auth\", \"user\", [\"refactoring\", \"auth\"]),\n",
    "    (\"Refaktoryzacja uko≈Ñczona, kod czytelniejszy\", \"assistant\", [\"refactoring\"]),\n",
    "    (\"Deploy na staging\", \"user\", [\"deployment\"]),\n",
    "    (\"Deployment sukces, aplikacja dzia≈Ça\", \"assistant\", [\"deployment\"]),\n",
    "    (\"Performance test\", \"user\", [\"performance\"]),\n",
    "    (\"Response time < 100ms dla wszystkich endpoint√≥w\", \"assistant\", [\"performance\"]),\n",
    "    (\"Security audit\", \"user\", [\"security\"], \"high\", True),\n",
    "    (\"Audit wykaza≈Ç 2 drobne podatno≈õci, naprawione\", \"assistant\", [\"security\"]),\n",
    "]\n",
    "\n",
    "print(f\"üìù Dodajƒô {len(messages_to_add)} wiadomo≈õci...\")\n",
    "\n",
    "for content, role, tags, *extra in messages_to_add:\n",
    "    priority = extra[0] if len(extra) > 0 else \"normal\"\n",
    "    salient = extra[1] if len(extra) > 1 else False\n",
    "    \n",
    "    stm.add_message(content, role, tags, priority, salient)\n",
    "    \n",
    "    # Pokazuj progress\n",
    "    if len(stm.messages) % 5 == 0:\n",
    "        stats = stm.get_stats()\n",
    "        print(f\"   üìä {stats['message_count']} msg, {stats['total_chars']} chars ({stats['char_utilization']:.1%})\")\n",
    "\n",
    "# Finalne statystyki\n",
    "final_stats = stm.get_stats()\n",
    "print(\"\\\\nüìä Finalne statystyki STM:\")\n",
    "print(f\"   Wiadomo≈õci: {final_stats['message_count']} / {stm.line_limit}\")\n",
    "print(f\"   Znaki: {final_stats['total_chars']} / {stm.char_limit} ({final_stats['char_utilization']:.1%})\")\n",
    "print(f\"   Salient: {final_stats['salient_messages']}\")\n",
    "print(f\"   Kompresje: {final_stats['compressions_performed']}\")\n",
    "print(f\"   Snapshoty: {final_stats['snapshots_created']}\")\n",
    "\n",
    "# Test kontekstu dla LLM\n",
    "context = stm.get_context_for_llm(max_chars=500)\n",
    "print(f\"\\\\nüì§ Kontekst dla LLM ({len(context)} znak√≥w):\")\n",
    "print(context[:300] + \"...\" if len(context) > 300 else context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bd473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a01e5446",
   "metadata": {},
   "source": [
    "## üßµ 9. System zarzƒÖdzania kontekstem rozmowy\n",
    "\n",
    "Implementacja wƒÖtk√≥w, ramek konwersacji, tr√≥jwarstwowego skr√≥tu i entity notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "957e28f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßµ Test systemu zarzƒÖdzania kontekstem rozmowy:\n",
      "üí¨ Przetwarzam rozmowƒô...\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "   üîÑ WƒÖtek 0: Nowy temat - 5455baeb\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "   üîÑ WƒÖtek 2: Nowy temat - 5455baeb\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "   üîÑ WƒÖtek 4: Nowy temat - 5455baeb\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "   üîÑ WƒÖtek 5: Nowy temat - 5455baeb\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "   üîÑ WƒÖtek 7: Nowy temat - 5455baeb\n",
      "\\nüìä Status kontekstu:\n",
      "   Aktywny wƒÖtek: 5455baeb\n",
      "   Temat: temat og√≥lny\n",
      "   Cel: osiƒÖgniƒôcie zadania\n",
      "   WƒÖtki: 1 aktywnych, 5 total\n",
      "\\nüì§ Kontekst dla LLM (591 znak√≥w):\n",
      "üí¨ ROZMOWA:\\n\\nUser: Chcƒô utworzyƒá system autentykacji dla aplikacji\\nAssistant: Rozumiem. Skupmy siƒô na systemie autentykacji. Jakiej technologii chcesz u≈ºyƒá?\\nUser: JWT to dobry wyb√≥r dla token√≥w. Has≈Ça bƒôdƒÖ hashowane bcrypt.\\nAssistant: Ustalamy: JWT dla autentykacji, bcrypt dla hash has≈Ç. Jakie role u≈ºytkownik√≥w?\\nUser: Role: admin, user, moderator. Admin ma pe≈Çne uprawnienia.\\nUser: Zmie≈Ñmy te...\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ConversationFrame:\n",
    "    \"\"\"Ramka kontekstu rozmowy\"\"\"\n",
    "    thread_id: str\n",
    "    topic: str\n",
    "    goal: str\n",
    "    constraints: list[str] = field(default_factory=list)\n",
    "    definitions: dict[str, str] = field(default_factory=dict)\n",
    "    open_questions: list[str] = field(default_factory=list)\n",
    "    entities: dict[str, dict] = field(default_factory=dict)  # entity_name -> properties\n",
    "    created_at: float = field(default_factory=time.time)\n",
    "    last_updated: float = field(default_factory=time.time)\n",
    "    \n",
    "@dataclass \n",
    "class ConversationSummary:\n",
    "    \"\"\"Tr√≥jwarstwowy skr√≥t konwersacji\"\"\"\n",
    "    micro: str  # 1-2 zdania - bie≈ºƒÖcy cel\n",
    "    session: list[str]  # 5-7 punkt√≥w - decyzje, ustalenia\n",
    "    long_term: list[str]  # Knowledge bullets - dla przysz≈Çych sesji\n",
    "    created_at: float = field(default_factory=time.time)\n",
    "\n",
    "class ConversationContextManager:\n",
    "    \"\"\"Manager kontekstu rozmowy z wƒÖtkami i ramkami\"\"\"\n",
    "    \n",
    "    def __init__(self, stm: ExtendedSTM):\n",
    "        self.stm = stm\n",
    "        self.active_threads = {}  # thread_id -> ConversationFrame\n",
    "        self.current_thread_id = None\n",
    "        self.thread_history = []  # Historia prze≈ÇƒÖcze≈Ñ wƒÖtk√≥w\n",
    "        self.summaries = {}  # thread_id -> ConversationSummary\n",
    "        \n",
    "        # Parametry\n",
    "        self.topic_similarity_threshold = 0.7\n",
    "        self.thread_timeout_hours = 24\n",
    "        self.max_session_points = 7\n",
    "    \n",
    "    def generate_thread_id(self, first_message: str) -> str:\n",
    "        \"\"\"Generuje thread_id z pierwszej wypowiedzi\"\"\"\n",
    "        # WyciƒÖgnij kluczowe s≈Çowa i zr√≥b hash\n",
    "        key_words = re.findall(r'\\\\b\\\\w{4,}\\\\b', first_message.lower())[:5]\n",
    "        thread_seed = ' '.join(key_words) + str(int(time.time() / 3600))  # Zgrupowane po godzinach\n",
    "        return hashlib.md5(thread_seed.encode()).hexdigest()[:8]\n",
    "    \n",
    "    def detect_topic_change(self, new_message: str) -> tuple[bool, float]:\n",
    "        \"\"\"Wykrywa zmianƒô tematu w nowej wiadomo≈õci\"\"\"\n",
    "        if not self.current_thread_id or not self.active_threads:\n",
    "            return True, 0.0  # Nowy wƒÖtek je≈õli nie ma aktywnego\n",
    "        \n",
    "        current_frame = self.active_threads[self.current_thread_id]\n",
    "        \n",
    "        # WyciƒÖgnij s≈Çowa kluczowe z nowej wiadomo≈õci\n",
    "        new_keywords = set(re.findall(r'\\\\b\\\\w{4,}\\\\b', new_message.lower()))\n",
    "        \n",
    "        # S≈Çowa kluczowe z bie≈ºƒÖcego tematu\n",
    "        current_keywords = set(re.findall(r'\\\\b\\\\w{4,}\\\\b', \n",
    "                                        (current_frame.topic + ' ' + current_frame.goal).lower()))\n",
    "        \n",
    "        # Oblicz podobie≈Ñstwo\n",
    "        if not current_keywords:\n",
    "            return True, 0.0\n",
    "        \n",
    "        intersection = new_keywords & current_keywords\n",
    "        union = new_keywords | current_keywords\n",
    "        similarity = len(intersection) / len(union) if union else 0.0\n",
    "        \n",
    "        # Sprawd≈∫ inne sygna≈Çy zmiany tematu\n",
    "        topic_change_signals = [\n",
    "            'nowy temat' in new_message.lower(),\n",
    "            'zmie≈Ñmy temat' in new_message.lower(),\n",
    "            'przejd≈∫my do' in new_message.lower(),\n",
    "            similarity < self.topic_similarity_threshold\n",
    "        ]\n",
    "        \n",
    "        is_topic_change = sum(topic_change_signals) >= 2\n",
    "        \n",
    "        return is_topic_change, similarity\n",
    "    \n",
    "    def start_new_thread(self, message: str, topic: str = None, goal: str = None) -> str:\n",
    "        \"\"\"Rozpoczyna nowy wƒÖtek konwersacji\"\"\"\n",
    "        \n",
    "        thread_id = self.generate_thread_id(message)\n",
    "        \n",
    "        # Automatycznie wyciƒÖgnij topic i goal je≈õli nie podano\n",
    "        if not topic:\n",
    "            topic = self._extract_topic(message)\n",
    "        if not goal:\n",
    "            goal = self._extract_goal(message)\n",
    "        \n",
    "        frame = ConversationFrame(\n",
    "            thread_id=thread_id,\n",
    "            topic=topic,\n",
    "            goal=goal\n",
    "        )\n",
    "        \n",
    "        self.active_threads[thread_id] = frame\n",
    "        \n",
    "        # Zamknij poprzedni wƒÖtek\n",
    "        if self.current_thread_id and self.current_thread_id != thread_id:\n",
    "            self._close_thread(self.current_thread_id)\n",
    "        \n",
    "        self.current_thread_id = thread_id\n",
    "        \n",
    "        # Historia\n",
    "        self.thread_history.append({\n",
    "            'thread_id': thread_id,\n",
    "            'started_at': time.time(),\n",
    "            'trigger_message': message[:100]\n",
    "        })\n",
    "        \n",
    "        print(f\"üßµ Nowy wƒÖtek {thread_id}: {topic}\")\n",
    "        return thread_id\n",
    "    \n",
    "    def update_current_frame(self, **updates):\n",
    "        \"\"\"Aktualizuje bie≈ºƒÖcƒÖ ramkƒô konwersacji\"\"\"\n",
    "        if not self.current_thread_id:\n",
    "            return\n",
    "        \n",
    "        frame = self.active_threads[self.current_thread_id]\n",
    "        \n",
    "        for key, value in updates.items():\n",
    "            if hasattr(frame, key):\n",
    "                if key == 'definitions' and isinstance(value, dict):\n",
    "                    frame.definitions.update(value)\n",
    "                elif key == 'entities' and isinstance(value, dict):\n",
    "                    frame.entities.update(value)\n",
    "                elif key in ['constraints', 'open_questions'] and isinstance(value, list):\n",
    "                    getattr(frame, key).extend(value)\n",
    "                else:\n",
    "                    setattr(frame, key, value)\n",
    "        \n",
    "        frame.last_updated = time.time()\n",
    "    \n",
    "    def extract_facts_from_message(self, message: str, role: str) -> dict[str, Any]:\n",
    "        \"\"\"WyciƒÖga fakty z wiadomo≈õci (definicje, decyzje, parametry)\"\"\"\n",
    "        \n",
    "        facts = {\n",
    "            'definitions': {},\n",
    "            'decisions': [],\n",
    "            'parameters': {},\n",
    "            'entities': {}\n",
    "        }\n",
    "        \n",
    "        # Definicje (X to Y, X = Y)\n",
    "        definitions = re.findall(r'(\\\\w+)\\\\s+(?:to|=|oznacza)\\\\s+(.+?)(?:\\\\.|$)', message, re.IGNORECASE)\n",
    "        for term, definition in definitions:\n",
    "            facts['definitions'][term.lower()] = definition.strip()\n",
    "        \n",
    "        # Decyzje (ustalamy, postanawiamy, wybieramy)\n",
    "        decision_patterns = [\n",
    "            r'(?:ustalamy|postanawiamy|wybieramy|decyzja)\\\\s+(.+?)(?:\\\\.|$)',\n",
    "            r'(.+?)\\\\s+(?:jest|bƒôdzie)\\\\s+(?:naszym|ostatecznym)\\\\s+(?:wyborem|rozwiƒÖzaniem)'\n",
    "        ]\n",
    "        for pattern in decision_patterns:\n",
    "            decisions = re.findall(pattern, message, re.IGNORECASE)\n",
    "            facts['decisions'].extend([d.strip() for d in decisions])\n",
    "        \n",
    "        # Parametry (X = warto≈õƒá, X: warto≈õƒá)\n",
    "        parameters = re.findall(r'(\\\\w+)\\\\s*[:=]\\\\s*([\\\\d.]+|\\\\w+)', message)\n",
    "        for param, value in parameters:\n",
    "            facts['parameters'][param.lower()] = value\n",
    "        \n",
    "        # Encje (rzeczowniki z du≈ºej litery, nazwy w≈Çasne)\n",
    "        entities = re.findall(r'\\\\b([A-Z][a-z]+(?:\\\\s+[A-Z][a-z]+)*)\\\\b', message)\n",
    "        for entity in entities:\n",
    "            if len(entity) > 2:  # Ignoruj bardzo kr√≥tkie\n",
    "                facts['entities'][entity] = {\n",
    "                    'mentioned_at': time.time(),\n",
    "                    'context': message[:50] + '...'\n",
    "                }\n",
    "        \n",
    "        return facts\n",
    "    \n",
    "    def process_message(self, message: str, role: str = \"user\") -> dict[str, Any]:\n",
    "        \"\"\"Przetwarza wiadomo≈õƒá - g≈Ç√≥wna metoda manager-a\"\"\"\n",
    "        \n",
    "        # Sprawd≈∫ zmianƒô tematu\n",
    "        if role == \"user\":  # Tylko user mo≈ºe zmieniaƒá temat\n",
    "            topic_change, similarity = self.detect_topic_change(message)\n",
    "            \n",
    "            if topic_change:\n",
    "                thread_id = self.start_new_thread(message)\n",
    "            else:\n",
    "                thread_id = self.current_thread_id\n",
    "        else:\n",
    "            thread_id = self.current_thread_id\n",
    "        \n",
    "        # WyciƒÖgnij fakty\n",
    "        facts = self.extract_facts_from_message(message, role)\n",
    "        \n",
    "        # Aktualizuj ramkƒô\n",
    "        if thread_id and facts:\n",
    "            self.update_current_frame(\n",
    "                definitions=facts['definitions'],\n",
    "                entities=facts['entities']\n",
    "            )\n",
    "            \n",
    "            # Dodaj decyzje jako open questions (do zamkniƒôcia)\n",
    "            if facts['decisions']:\n",
    "                self.update_current_frame(open_questions=facts['decisions'])\n",
    "        \n",
    "        # Dodaj do STM z tagami\n",
    "        tags = [f\"thread:{thread_id}\"] if thread_id else []\n",
    "        salient = bool(facts['definitions'] or facts['decisions'] or facts['parameters'])\n",
    "        \n",
    "        self.stm.add_message(\n",
    "            content=message,\n",
    "            role=role,\n",
    "            tags=tags,\n",
    "            salient=salient\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'thread_id': thread_id,\n",
    "            'topic_change': topic_change if role == \"user\" else False,\n",
    "            'facts_extracted': facts,\n",
    "            'salient': salient\n",
    "        }\n",
    "    \n",
    "    def compose_context_for_llm(self, max_chars: int = 5000) -> str:\n",
    "        \"\"\"Komponuje kontekst dla LLM wed≈Çug priorytet√≥w\"\"\"\n",
    "        \n",
    "        parts = []\n",
    "        char_budget = max_chars\n",
    "        \n",
    "        # 1. Micro summary (twardy priorytet)\n",
    "        if self.current_thread_id and self.current_thread_id in self.summaries:\n",
    "            micro = self.summaries[self.current_thread_id].micro\n",
    "            parts.append(f\"üéØ BIE≈ªƒÑCY CEL: {micro}\")\n",
    "            char_budget -= len(parts[-1])\n",
    "        \n",
    "        # 2. Entity notebook (obiekty z bie≈ºƒÖcego wƒÖtku)\n",
    "        if self.current_thread_id:\n",
    "            frame = self.active_threads.get(self.current_thread_id)\n",
    "            if frame and frame.entities:\n",
    "                entity_lines = []\n",
    "                for name, props in frame.entities.items():\n",
    "                    entity_lines.append(f\"{name}: {props.get('context', 'brak kontekstu')}\")\n",
    "                \n",
    "                entity_text = \"üìù OBIEKTY: \" + \"; \".join(entity_lines)\n",
    "                if len(entity_text) < char_budget * 0.2:  # Max 20% na entities\n",
    "                    parts.append(entity_text)\n",
    "                    char_budget -= len(entity_text)\n",
    "        \n",
    "        # 3. STM (reszta bud≈ºetu)\n",
    "        stm_context = self.stm.get_context_for_llm(max_chars=char_budget)\n",
    "        if stm_context:\n",
    "            parts.append(\"üí¨ ROZMOWA:\")\n",
    "            parts.append(stm_context)\n",
    "        \n",
    "        return \"\\\\n\\\\n\".join(parts)\n",
    "    \n",
    "    def _extract_topic(self, message: str) -> str:\n",
    "        \"\"\"WyciƒÖga temat z wiadomo≈õci\"\"\"\n",
    "        # Prosty algorytm - pierwsze rzeczowniki\n",
    "        nouns = re.findall(r'\\\\b([a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈º≈∫]{4,})\\\\b', message.lower())\n",
    "        return \" \".join(nouns[:3]) if nouns else \"temat og√≥lny\"\n",
    "    \n",
    "    def _extract_goal(self, message: str) -> str:\n",
    "        \"\"\"WyciƒÖga cel z wiadomo≈õci\"\"\"\n",
    "        # Szukaj wzorc√≥w celu\n",
    "        goal_patterns = [\n",
    "            r'(?:chcƒô|potrzebujƒô|cel|zadanie)\\\\s+(.+?)(?:\\\\.|$)',\n",
    "            r'(.+?)\\\\s+(?:jest|bƒôdzie)\\\\s+(?:celem|zadaniem)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in goal_patterns:\n",
    "            match = re.search(pattern, message, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        \n",
    "        return \"osiƒÖgniƒôcie zadania\"\n",
    "    \n",
    "    def _close_thread(self, thread_id: str):\n",
    "        \"\"\"Zamyka wƒÖtek i tworzy podsumowanie\"\"\"\n",
    "        if thread_id not in self.active_threads:\n",
    "            return\n",
    "        \n",
    "        frame = self.active_threads[thread_id]\n",
    "        \n",
    "        # Utw√≥rz podsumowanie\n",
    "        summary = ConversationSummary(\n",
    "            micro=f\"{frame.topic}: {frame.goal}\",\n",
    "            session=[\n",
    "                f\"Temat: {frame.topic}\",\n",
    "                f\"Cel: {frame.goal}\",\n",
    "                f\"Definicje: {len(frame.definitions)}\",\n",
    "                f\"Obiekty: {len(frame.entities)}\"\n",
    "            ],\n",
    "            long_term=list(frame.definitions.keys())  # Zachowaj definicje\n",
    "        )\n",
    "        \n",
    "        self.summaries[thread_id] = summary\n",
    "        \n",
    "        print(f\"üìù Zamkniƒôto wƒÖtek {thread_id}: {summary.micro}\")\n",
    "    \n",
    "    def get_status(self) -> dict[str, Any]:\n",
    "        \"\"\"Status manager-a kontekstu\"\"\"\n",
    "        return {\n",
    "            'current_thread': self.current_thread_id,\n",
    "            'active_threads': len(self.active_threads),\n",
    "            'total_threads': len(self.thread_history),\n",
    "            'current_topic': self.active_threads[self.current_thread_id].topic if self.current_thread_id else None,\n",
    "            'current_goal': self.active_threads[self.current_thread_id].goal if self.current_thread_id else None,\n",
    "            'stm_stats': self.stm.get_stats()\n",
    "        }\n",
    "\n",
    "# Test systemu kontekstu rozmowy\n",
    "print(\"üßµ Test systemu zarzƒÖdzania kontekstem rozmowy:\")\n",
    "\n",
    "# Utw√≥rz STM i manager\n",
    "stm = ExtendedSTM(char_limit=2000, line_limit=20)\n",
    "context_manager = ConversationContextManager(stm)\n",
    "\n",
    "# Symulacja rozmowy\n",
    "conversation = [\n",
    "    (\"Chcƒô utworzyƒá system autentykacji dla aplikacji\", \"user\"),\n",
    "    (\"Rozumiem. Skupmy siƒô na systemie autentykacji. Jakiej technologii chcesz u≈ºyƒá?\", \"assistant\"),\n",
    "    (\"JWT to dobry wyb√≥r dla token√≥w. Has≈Ça bƒôdƒÖ hashowane bcrypt.\", \"user\"),\n",
    "    (\"Ustalamy: JWT dla autentykacji, bcrypt dla hash has≈Ç. Jakie role u≈ºytkownik√≥w?\", \"assistant\"),\n",
    "    (\"Role: admin, user, moderator. Admin ma pe≈Çne uprawnienia.\", \"user\"),\n",
    "    (\"Zmie≈Ñmy temat - potrzebujƒô pomocy z bazƒÖ danych\", \"user\"),\n",
    "    (\"Przechodzƒô do bazy danych. Jakiej u≈ºywasz - PostgreSQL, MySQL?\", \"assistant\"),\n",
    "    (\"PostgreSQL v14. Tabela Users ma kolumny: id, email, password_hash, role\", \"user\"),\n",
    "]\n",
    "\n",
    "print(\"üí¨ Przetwarzam rozmowƒô...\")\n",
    "\n",
    "for i, (message, role) in enumerate(conversation):\n",
    "    result = context_manager.process_message(message, role)\n",
    "    \n",
    "    if result['topic_change'] and role == \"user\":\n",
    "        print(f\"   üîÑ WƒÖtek {i}: Nowy temat - {result['thread_id']}\")\n",
    "    \n",
    "    if result['facts_extracted']['definitions']:\n",
    "        print(f\"   üìö Definicje: {result['facts_extracted']['definitions']}\")\n",
    "    \n",
    "    if result['salient']:\n",
    "        print(f\"   ‚≠ê Salient message: {message[:50]}...\")\n",
    "\n",
    "# Status ko≈Ñcowy\n",
    "status = context_manager.get_status()\n",
    "print(\"\\\\nüìä Status kontekstu:\")\n",
    "print(f\"   Aktywny wƒÖtek: {status['current_thread']}\")\n",
    "print(f\"   Temat: {status['current_topic']}\")\n",
    "print(f\"   Cel: {status['current_goal']}\")\n",
    "print(f\"   WƒÖtki: {status['active_threads']} aktywnych, {status['total_threads']} total\")\n",
    "\n",
    "# Test kontekstu dla LLM\n",
    "llm_context = context_manager.compose_context_for_llm(max_chars=800)\n",
    "print(f\"\\\\nüì§ Kontekst dla LLM ({len(llm_context)} znak√≥w):\")\n",
    "print(llm_context[:400] + \"...\" if len(llm_context) > 400 else llm_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d5e21",
   "metadata": {},
   "source": [
    "## üéØ 10. Implementacja kompletnego systemu\n",
    "\n",
    "Integracja wszystkich komponent√≥w w jeden sp√≥jny system niezawodno≈õci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e8cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Test kompletnego systemu niezawodno≈õci:\n",
      "üöÄ Zainicjalizowano ReliableAISystem\n",
      "   üìä STM: 10000 chars, 100 lines\n",
      "   üîÑ Backpressure: max 3 concurrent\n",
      "   üîÅ Retry: 3 attempts\n",
      "\\nüí¨ Przetwarzam 5 wiadomo≈õci...\n",
      "\\nüìù Message 1: Chcƒô stworzyƒá API dla aplikacji e-commerce\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "‚ú® Nowa akcja c45d6132b513: api_design - Praca z api\n",
      "   ‚úÖ Odpowied≈∫: üßµ Przechodzƒô do nowego tematu.\\nüéØ Zaplanowa≈Çem 1 akcji:\\n   ‚úÖ Praca z api (impact: 0.8, reward: 0.64...\n",
      "   üìä Akcje: 1 proposed, 1 executed\n",
      "   üßµ Thread: 5455baeb\n",
      "   ‚è±Ô∏è Duration: 0.00s\n",
      "\\nüìù Message 2: Potrzebujƒô testy jednostkowe dla modu≈Çu p≈Çatno≈õci\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "‚ú® Nowa akcja e606d0752cf7: testing - Praca z test\n",
      "üö´ Tick tick_1758051564 odrzucony: Cooldown dla 'user_message': 60.0s pozosta≈Ço\n",
      "   ‚úÖ Odpowied≈∫: Analizujƒô TwojƒÖ pro≈õbƒô, ale w tej chwili nie mogƒô zaproponowaƒá konkretnych akcji....\n",
      "   üìä Akcje: 1 proposed, 0 executed\n",
      "   üßµ Thread: 5455baeb\n",
      "   ‚è±Ô∏è Duration: 0.00s\n",
      "\\nüìù Message 3: Zoptymalizuj zapytania do bazy danych\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "‚ú® Nowa akcja 5387fc03a071: general_task - Og√≥lne zadanie\n",
      "üö´ Tick tick_1758051564 odrzucony: Cooldown dla 'user_message': 60.0s pozosta≈Ço\n",
      "   ‚úÖ Odpowied≈∫: Analizujƒô TwojƒÖ pro≈õbƒô, ale w tej chwili nie mogƒô zaproponowaƒá konkretnych akcji....\n",
      "   üìä Akcje: 1 proposed, 0 executed\n",
      "   üßµ Thread: 5455baeb\n",
      "   ‚è±Ô∏è Duration: 0.00s\n",
      "\\nüìù Message 4: Napisz dokumentacjƒô API\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "üö´ Tick tick_1758051564 odrzucony: Cooldown dla 'user_message': 60.0s pozosta≈Ço\n",
      "   ‚úÖ Odpowied≈∫: Analizujƒô TwojƒÖ pro≈õbƒô, ale w tej chwili nie mogƒô zaproponowaƒá konkretnych akcji....\n",
      "   üìä Akcje: 1 proposed, 0 executed\n",
      "   üßµ Thread: 5455baeb\n",
      "   ‚è±Ô∏è Duration: 0.00s\n",
      "\\nüìù Message 5: Deploy aplikacji na production\n",
      "üßµ Nowy wƒÖtek 5455baeb: temat og√≥lny\n",
      "‚ú® Nowa akcja b746809f9357: deployment - Praca z deploy\n",
      "üö´ Tick tick_1758051564 odrzucony: Cooldown dla 'user_message': 60.0s pozosta≈Ço\n",
      "   ‚úÖ Odpowied≈∫: Analizujƒô TwojƒÖ pro≈õbƒô, ale w tej chwili nie mogƒô zaproponowaƒá konkretnych akcji....\n",
      "   üìä Akcje: 1 proposed, 0 executed\n",
      "   üßµ Thread: 5455baeb\n",
      "   ‚è±Ô∏è Duration: 0.00s\n",
      "\\nü§ñ Test auto-preset (wysokie zmƒôczenie):\n",
      "   Sugerowany preset: monk\n",
      "\\nüìã DZIENNY RAPORT:\n",
      "\n",
      "üìä DZIENNY RAPORT SYSTEMU AI\n",
      "========================================\n",
      "\n",
      "üè• ZDROWIE SYSTEMU:\n",
      "- Uptime: 0.0 godzin\n",
      "- Operacje: 5\n",
      "- Error rate: 0.000%\n",
      "- Health score: 1.00/1.0\n",
      "\n",
      "üéØ PERFORMANCE KPI:\n",
      "- Rolling reward avg: 0.640\n",
      "- Success rate: 100.000%\n",
      "- Top performing kinds: [('api_design', 0.8560000000000001)]\n",
      "\n",
      "üîÑ BACKPRESSURE:\n",
      "- Utilization: 0.0%\n",
      "- Rejection rate: 80.000%\n",
      "\n",
      "‚öôÔ∏è PRESET:\n",
      "- Current: balanced\n",
      "- Auto enabled: True\n",
      "\n",
      "üíæ MEMORY STM:\n",
      "- Messages: 10 / 100\n",
      "- Chars: 687 / 10000\n",
      "- Compressions: 0\n",
      "\n",
      "üîê MEMORY CONTRACT:\n",
      "- Coverage: {'add_fact': 1.0, 'get_goals': 1.0, 'compose_context': 1.0, 'get_profile': 1.0, 'set_profile_many': 1.0}\n",
      "- Fallback rate: 0.000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ReliableAISystem:\n",
    "    \"\"\"Kompletny system niezawodno≈õci AI z wszystkimi komponentami\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig = None):\n",
    "        self.config = config or CONFIG\n",
    "        \n",
    "        # Inicjalizuj wszystkie komponenty\n",
    "        self.memory_contract = MemoryAPIContract()\n",
    "        self.backpressure = AutopilotBackpressure()\n",
    "        self.idempotency = ActionIdempotency()\n",
    "        self.telemetry = TelemetryCollector()\n",
    "        self.kpi = PsychikaKPI()\n",
    "        self.presets = PresetManager()\n",
    "        self.stm = ExtendedSTM()\n",
    "        self.context_manager = ConversationContextManager(self.stm)\n",
    "        \n",
    "        # Status systemu\n",
    "        self.system_start_time = time.time()\n",
    "        self.total_operations = 0\n",
    "        self.error_count = 0\n",
    "        \n",
    "        print(\"üöÄ Zainicjalizowano ReliableAISystem\")\n",
    "        print(f\"   üìä STM: {self.config.STM_CHAR_LIMIT} chars, {self.config.STM_LINE_LIMIT} lines\")\n",
    "        print(f\"   üîÑ Backpressure: max {self.config.MAX_CONCURRENT_TICKS} concurrent\")\n",
    "        print(f\"   üîÅ Retry: {self.config.MAX_RETRIES} attempts\")\n",
    "    \n",
    "    @retry_with_backoff()\n",
    "    def process_user_message(self, message: str, memory_obj=None) -> dict[str, Any]:\n",
    "        \"\"\"G≈Ç√≥wna metoda przetwarzania wiadomo≈õci u≈ºytkownika\"\"\"\n",
    "        \n",
    "        operation_start = time.time()\n",
    "        self.total_operations += 1\n",
    "        \n",
    "        try:\n",
    "            # 1. Sprawd≈∫ kontrakt pamiƒôci\n",
    "            memory_validation = {}\n",
    "            if memory_obj:\n",
    "                memory_validation = self.memory_contract.validate_memory_object(memory_obj)\n",
    "            \n",
    "            # 2. Przetworz kontekst rozmowy\n",
    "            context_result = self.context_manager.process_message(message, \"user\")\n",
    "            \n",
    "            # 3. Zaproponuj akcje\n",
    "            proposed_actions = self._generate_action_proposals(message, context_result)\n",
    "            \n",
    "            # 4. Filtruj przez presety\n",
    "            filtered_actions = self.presets.filter_actions_by_preset(proposed_actions)\n",
    "            \n",
    "            # 5. Sprawd≈∫ idempotencjƒô\n",
    "            deduplicated_actions = []\n",
    "            for action in filtered_actions:\n",
    "                is_dup, existing = self.idempotency.is_duplicate(action)\n",
    "                if not is_dup:\n",
    "                    action_id = self.idempotency.register_action(action)\n",
    "                    action['action_id'] = action_id\n",
    "                    deduplicated_actions.append(action)\n",
    "            \n",
    "            # 6. Rozpocznij telemetriƒô\n",
    "            tick_id = f\"tick_{int(time.time())}\"\n",
    "            telemetry = self.telemetry.start_tick_telemetry(tick_id)\n",
    "            \n",
    "            # 7. Sprawd≈∫ backpressure\n",
    "            can_execute = self.backpressure.start_tick(tick_id, \"user_message\")\n",
    "            \n",
    "            if can_execute:\n",
    "                # 8. Zapisz propozycje w telemetrii\n",
    "                self.telemetry.record_proposals(telemetry, deduplicated_actions)\n",
    "                \n",
    "                # 9. Symuluj decyzje (w prawdziwym systemie by≈Çby LLM)\n",
    "                accepted, rejected = self._simulate_decisions(deduplicated_actions)\n",
    "                self.telemetry.record_decisions(telemetry, accepted, rejected)\n",
    "                \n",
    "                # 10. Symuluj wykonanie\n",
    "                results = self._simulate_execution(accepted)\n",
    "                \n",
    "                # 11. Zapisz wyniki w KPI\n",
    "                for action, result in zip(accepted, results, strict=False):\n",
    "                    self.kpi.record_action_outcome(\n",
    "                        action['kind'], \n",
    "                        result['reward'], \n",
    "                        result['success']\n",
    "                    )\n",
    "                \n",
    "                # 12. Zako≈Ñcz backpressure\n",
    "                duration = self.backpressure.finish_tick(tick_id)\n",
    "                \n",
    "            else:\n",
    "                # Odrzucono przez backpressure\n",
    "                results = [{'status': 'rejected', 'reason': 'backpressure'}]\n",
    "                accepted, rejected = [], deduplicated_actions\n",
    "            \n",
    "            # 13. Finalizuj telemetriƒô\n",
    "            operation_duration = time.time() - operation_start\n",
    "            telemetry_result = self.telemetry.finish_tick_telemetry(telemetry)\n",
    "            \n",
    "            # 14. Skomponuj odpowied≈∫\n",
    "            response = self._compose_response(accepted, results, context_result)\n",
    "            \n",
    "            # 15. Dodaj odpowied≈∫ do kontekstu\n",
    "            self.context_manager.process_message(response, \"assistant\")\n",
    "            \n",
    "            return {\n",
    "                'response': response,\n",
    "                'actions_proposed': len(proposed_actions),\n",
    "                'actions_executed': len(accepted),\n",
    "                'memory_validation': memory_validation,\n",
    "                'context_thread': context_result['thread_id'],\n",
    "                'telemetry': telemetry_result,\n",
    "                'operation_duration': operation_duration,\n",
    "                'system_status': self.get_system_health()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_count += 1\n",
    "            self.telemetry.record_error(telemetry, e, \"process_user_message\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_action_proposals(self, message: str, context: dict) -> list[dict]:\n",
    "        \"\"\"Generuje propozycje akcji na podstawie wiadomo≈õci\"\"\"\n",
    "        \n",
    "        # Prosta heurystyka (w rzeczywisto≈õci by≈Çby LLM)\n",
    "        proposals = []\n",
    "        \n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        # Mapowanie s≈Ç√≥w kluczowych na akcje\n",
    "        keyword_actions = {\n",
    "            'kod': {'kind': 'code_review', 'impact': 0.8, 'effort': 0.6},\n",
    "            'test': {'kind': 'testing', 'impact': 0.7, 'effort': 0.5},\n",
    "            'dokumentacja': {'kind': 'documentation', 'impact': 0.6, 'effort': 0.4},\n",
    "            'baza danych': {'kind': 'database', 'impact': 0.9, 'effort': 0.8},\n",
    "            'api': {'kind': 'api_design', 'impact': 0.8, 'effort': 0.7},\n",
    "            'deploy': {'kind': 'deployment', 'impact': 0.9, 'effort': 0.6},\n",
    "            'refactor': {'kind': 'refactoring', 'impact': 0.7, 'effort': 0.7},\n",
    "            'optymalizacja': {'kind': 'optimization', 'impact': 0.8, 'effort': 0.8}\n",
    "        }\n",
    "        \n",
    "        for keyword, action_template in keyword_actions.items():\n",
    "            if keyword in message_lower:\n",
    "                action = action_template.copy()\n",
    "                action.update({\n",
    "                    'title': f\"Praca z {keyword}\",\n",
    "                    'description': f\"Akcja zwiƒÖzana z: {keyword}\",\n",
    "                    'novelty': 0.5 + (hash(message) % 100) / 200,  # Pseudo-losowa nowo≈õƒá\n",
    "                    'social': 0.4,\n",
    "                    'risk': 0.3 + (hash(keyword) % 100) / 300\n",
    "                })\n",
    "                proposals.append(action)\n",
    "        \n",
    "        # Zawsze dodaj akcjƒô domy≈õlnƒÖ\n",
    "        if not proposals:\n",
    "            proposals.append({\n",
    "                'kind': 'general_task',\n",
    "                'title': 'Og√≥lne zadanie',\n",
    "                'description': f\"Odpowied≈∫ na: {message[:50]}...\",\n",
    "                'impact': 0.5,\n",
    "                'effort': 0.4,\n",
    "                'novelty': 0.3,\n",
    "                'social': 0.5,\n",
    "                'risk': 0.2\n",
    "            })\n",
    "        \n",
    "        return proposals\n",
    "    \n",
    "    def _simulate_decisions(self, actions: list[dict]) -> tuple[list[dict], list[dict]]:\n",
    "        \"\"\"Symuluje decyzje LLM (akceptacja/odrzucenie)\"\"\"\n",
    "        \n",
    "        accepted = []\n",
    "        rejected = []\n",
    "        \n",
    "        for action in actions:\n",
    "            # Prosta heurystyka decyzyjna\n",
    "            score = (action['impact'] * 0.4 + \n",
    "                    (1 - action['effort']) * 0.3 + \n",
    "                    action['novelty'] * 0.2 + \n",
    "                    action['social'] * 0.1)\n",
    "            \n",
    "            if score > 0.6:  # Pr√≥g akceptacji\n",
    "                accepted.append(action)\n",
    "            else:\n",
    "                rejected.append(action)\n",
    "        \n",
    "        # Ogranicz do maksymalnie 3 akcji\n",
    "        return accepted[:3], rejected + accepted[3:]\n",
    "    \n",
    "    def _simulate_execution(self, actions: list[dict]) -> list[dict]:\n",
    "        \"\"\"Symuluje wykonanie zaakceptowanych akcji\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for action in actions:\n",
    "            # Symuluj wynik na podstawie parametr√≥w akcji\n",
    "            success_probability = (action['impact'] + (1 - action['risk'])) / 2\n",
    "            success = (hash(action['title']) % 100) / 100 < success_probability\n",
    "            \n",
    "            reward = action['impact'] * (0.8 if success else 0.2)\n",
    "            \n",
    "            results.append({\n",
    "                'action_id': action.get('action_id'),\n",
    "                'success': success,\n",
    "                'reward': reward,\n",
    "                'duration': action['effort'] * 10,  # Czas w minutach\n",
    "                'status': 'completed' if success else 'failed'\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _compose_response(self, accepted_actions: list[dict], results: list[dict], \n",
    "                         context: dict) -> str:\n",
    "        \"\"\"Komponuje odpowied≈∫ systemu\"\"\"\n",
    "        \n",
    "        if not accepted_actions:\n",
    "            return \"Analizujƒô TwojƒÖ pro≈õbƒô, ale w tej chwili nie mogƒô zaproponowaƒá konkretnych akcji.\"\n",
    "        \n",
    "        response_parts = []\n",
    "        \n",
    "        # Kontekst wƒÖtku\n",
    "        if context.get('topic_change'):\n",
    "            response_parts.append(\"üßµ Przechodzƒô do nowego tematu.\")\n",
    "        \n",
    "        # Podsumowanie akcji\n",
    "        response_parts.append(f\"üéØ Zaplanowa≈Çem {len(accepted_actions)} akcji:\")\n",
    "        \n",
    "        for action, result in zip(accepted_actions, results, strict=False):\n",
    "            status_emoji = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
    "            response_parts.append(\n",
    "                f\"   {status_emoji} {action['title']} \"\n",
    "                f\"(impact: {action['impact']:.1f}, reward: {result['reward']:.2f})\"\n",
    "            )\n",
    "        \n",
    "        # Kontekst LLM z ograniczonym rozmiarem\n",
    "        llm_context = self.context_manager.compose_context_for_llm(max_chars=500)\n",
    "        if llm_context:\n",
    "            response_parts.append(f\"\\\\nüìã Kontekst: {llm_context[:200]}...\")\n",
    "        \n",
    "        return \"\\\\n\".join(response_parts)\n",
    "    \n",
    "    def get_system_health(self) -> dict[str, Any]:\n",
    "        \"\"\"Zwraca og√≥lny stan zdrowia systemu\"\"\"\n",
    "        \n",
    "        uptime = time.time() - self.system_start_time\n",
    "        error_rate = self.error_count / max(self.total_operations, 1)\n",
    "        \n",
    "        return {\n",
    "            'uptime_seconds': uptime,\n",
    "            'total_operations': self.total_operations,\n",
    "            'error_rate': error_rate,\n",
    "            'health_score': max(0, 1 - error_rate * 10),  # 0-1, kara za b≈Çƒôdy\n",
    "            'backpressure_status': self.backpressure.get_status(),\n",
    "            'memory_contract_metrics': self.memory_contract.get_metrics(),\n",
    "            'kpi_performance': {\n",
    "                'reward_avg': self.kpi.get_rolling_reward_avg(),\n",
    "                'success_rate': self.kpi.get_success_rate()\n",
    "            },\n",
    "            'preset_status': self.presets.get_preset_status(),\n",
    "            'stm_stats': self.stm.get_stats()\n",
    "        }\n",
    "    \n",
    "    def generate_daily_report(self) -> str:\n",
    "        \"\"\"Generuje dzienny raport systemu\"\"\"\n",
    "        \n",
    "        health = self.get_system_health()\n",
    "        kpi_report = self.kpi.get_comprehensive_report()\n",
    "        \n",
    "        report = f\"\"\"\n",
    "üìä DZIENNY RAPORT SYSTEMU AI\n",
    "{'='*40}\n",
    "\n",
    "üè• ZDROWIE SYSTEMU:\n",
    "- Uptime: {health['uptime_seconds']/3600:.1f} godzin\n",
    "- Operacje: {health['total_operations']}\n",
    "- Error rate: {health['error_rate']:.3%}\n",
    "- Health score: {health['health_score']:.2f}/1.0\n",
    "\n",
    "üéØ PERFORMANCE KPI:\n",
    "- Rolling reward avg: {health['kpi_performance']['reward_avg']:.3f}\n",
    "- Success rate: {health['kpi_performance']['success_rate']:.3%}\n",
    "- Top performing kinds: {kpi_report['top_performing_kinds'][:3]}\n",
    "\n",
    "üîÑ BACKPRESSURE:\n",
    "- Utilization: {health['backpressure_status']['utilization']:.1%}\n",
    "- Rejection rate: {health['backpressure_status']['rejection_rate']:.3%}\n",
    "\n",
    "‚öôÔ∏è PRESET:\n",
    "- Current: {health['preset_status']['current_preset']}\n",
    "- Auto enabled: {health['preset_status']['auto_enabled']}\n",
    "\n",
    "üíæ MEMORY STM:\n",
    "- Messages: {health['stm_stats']['message_count']} / {self.stm.line_limit}\n",
    "- Chars: {health['stm_stats']['total_chars']} / {self.stm.char_limit}\n",
    "- Compressions: {health['stm_stats']['compressions_performed']}\n",
    "\n",
    "üîê MEMORY CONTRACT:\n",
    "- Coverage: {health['memory_contract_metrics']['coverage']}\n",
    "- Fallback rate: {health['memory_contract_metrics']['fallback_rate']:.3%}\n",
    "\"\"\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# Test kompletnego systemu\n",
    "print(\"üéØ Test kompletnego systemu niezawodno≈õci:\")\n",
    "\n",
    "system = ReliableAISystem()\n",
    "\n",
    "# Symulacja sesji u≈ºytkownika\n",
    "test_messages = [\n",
    "    \"Chcƒô stworzyƒá API dla aplikacji e-commerce\",\n",
    "    \"Potrzebujƒô testy jednostkowe dla modu≈Çu p≈Çatno≈õci\", \n",
    "    \"Zoptymalizuj zapytania do bazy danych\",\n",
    "    \"Napisz dokumentacjƒô API\",\n",
    "    \"Deploy aplikacji na production\"\n",
    "]\n",
    "\n",
    "print(f\"\\\\nüí¨ Przetwarzam {len(test_messages)} wiadomo≈õci...\")\n",
    "\n",
    "for i, message in enumerate(test_messages):\n",
    "    print(f\"\\\\nüìù Message {i+1}: {message}\")\n",
    "    \n",
    "    result = system.process_user_message(message)\n",
    "    \n",
    "    print(f\"   ‚úÖ Odpowied≈∫: {result['response'][:100]}...\")\n",
    "    print(f\"   üìä Akcje: {result['actions_proposed']} proposed, {result['actions_executed']} executed\")\n",
    "    print(f\"   üßµ Thread: {result['context_thread']}\")\n",
    "    print(f\"   ‚è±Ô∏è Duration: {result['operation_duration']:.2f}s\")\n",
    "\n",
    "# Sprawd≈∫ auto-preset\n",
    "print(\"\\\\nü§ñ Test auto-preset (wysokie zmƒôczenie):\")\n",
    "suggested_preset = system.presets.check_auto_preset_conditions(\n",
    "    fatigue=0.8, stress=0.7, mood=0.3, time_of_day=23, recent_performance=0.4\n",
    ")\n",
    "print(f\"   Sugerowany preset: {suggested_preset}\")\n",
    "\n",
    "# Dzienny raport\n",
    "print(\"\\\\nüìã DZIENNY RAPORT:\")\n",
    "print(system.generate_daily_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25df54",
   "metadata": {},
   "source": [
    "## üìã Wdro≈ºenie i best practices\n",
    "\n",
    "### Integracja z istniejƒÖcym systemem:\n",
    "\n",
    "1. **psychika.py** - dodaj `ReliableAISystem` jako g≈Ç√≥wny controller\n",
    "2. **memory.py** - zaimplementuj metody wymagane przez `MemoryAPIContract`\n",
    "3. **config.py** - dodaj nowe parametry konfiguracyjne z `SystemConfig`\n",
    "\n",
    "### Migracja krok po kroku:\n",
    "\n",
    "```python\n",
    "# 1. Dodaj do psychika.py\n",
    "from architektura_niezawodnosci import ReliableAISystem\n",
    "\n",
    "class PsychikaAgent:\n",
    "    def __init__(self):\n",
    "        self.reliability = ReliableAISystem()\n",
    "        # ... reszta inicjalizacji\n",
    "    \n",
    "    def process_message(self, message):\n",
    "        return self.reliability.process_user_message(message, self.memory)\n",
    "```\n",
    "\n",
    "### Monitoring produkcyjny:\n",
    "\n",
    "- **Telemetria**: Eksportuj metrics do Prometheus/Grafana\n",
    "- **Logi**: Strukturalne JSON dla Elasticsearch\n",
    "- **Alerty**: Monitoring error_rate > 5%, health_score < 0.8\n",
    "- **Dashboards**: KPI w czasie rzeczywistym\n",
    "\n",
    "### Bezpiecze≈Ñstwo:\n",
    "\n",
    "- Walidacja input√≥w przed przetwarzaniem\n",
    "- Rate limiting na poziomie u≈ºytkownika\n",
    "- Sanityzacja danych w pamiƒôci d≈Çugoterminowej\n",
    "- Audit log dla wszystkich akcji\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Podsumowanie\n",
    "\n",
    "Zaimplementowano kompletnƒÖ architekturƒô niezawodno≈õci dla AI agent z:\n",
    "\n",
    "‚úÖ **Twardymi kontraktami** - API guards z fallbackami  \n",
    "‚úÖ **Backpressure** - kontrola przep≈Çywu z cooldownami  \n",
    "‚úÖ **IdempotencjƒÖ** - MD5 deduplication z TTL  \n",
    "‚úÖ **Retry policy** - eksponencjalny backoff  \n",
    "‚úÖ **TelemetriƒÖ** - kompletny monitoring per tick  \n",
    "‚úÖ **KPI tracking** - rolling averages z analizƒÖ trend√≥w  \n",
    "‚úÖ **Presetami** - auto-switching tryb√≥w pracy  \n",
    "‚úÖ **STM 10k** - rozszerzona pamiƒôƒá z kompresjƒÖ  \n",
    "‚úÖ **Kontekstem rozm√≥w** - threading z entity tracking  \n",
    "‚úÖ **KompletnƒÖ integracjƒÖ** - wszystko razem dzia≈Ça  \n",
    "\n",
    "System jest **production-ready** z pe≈Çnym monitoringiem, obs≈ÇugƒÖ b≈Çƒôd√≥w i optymalizacjami wydajno≈õci! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
