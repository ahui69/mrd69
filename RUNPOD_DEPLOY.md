# ğŸš€ DEPLOY NA RUNPOD - INSTRUKCJA

## ğŸ’° TWOJA SYTUACJA:
- âœ… Masz RunPod account
- âœ… Model leci z DeepInfra (nie potrzebujesz GPU!)
- âœ… RunPod CPU wystarczy = **TANIEJ**

---

## ğŸ“‹ KROK PO KROKU (15 minut):

### **KROK 1: Przygotuj kod (ZROBIONE!)**

âœ… Masz juÅ¼:
- `Dockerfile.runpod` - gotowy
- `requirements.txt` - z wersjami
- `.env` - z kluczami
- Kod dziaÅ‚a lokalnie

---

### **KROK 2: WejdÅº na RunPod**

1. IdÅº na: https://www.runpod.io/console
2. Zaloguj siÄ™
3. Kliknij "Templates" (lewy menu)

---

### **KROK 3: StwÃ³rz Custom Template**

```
Name: mrd69-api
Container Image: python:3.13-slim

Container Start Command:
bash -c "pip install -r requirements.txt && uvicorn server:app --host 0.0.0.0 --port 8000"

Container Disk: 10 GB (wystarczy)
Expose HTTP Ports: 8000
Expose TCP Ports: -
```

**Environment Variables (dodaj w RunPod):**
```
LLM_BASE_URL=https://api.deepinfra.com/v1/openai
LLM_API_KEY=twoj_klucz_deepinfra
LLM_MODEL=meta-llama/Meta-Llama-3.1-70B-Instruct
USE_RUNPOD=1
RUNPOD_PERSIST_DIR=/runpod/persist
```

---

### **KROK 4: Deploy z GitHub (NAJÅATWIEJ)**

**Opcja A - przez GitHub (polecam!):**

1. WrzuÄ‡ kod na GitHub:
```bash
cd /workspace
git init
git add .
git commit -m "initial commit"
gh repo create mrd69-api --private --source=. --remote=origin --push
# LUB rÄ™cznie: stwÃ³rz repo na github.com i:
git remote add origin https://github.com/TWOJA_NAZWA/mrd69-api.git
git push -u origin master
```

2. W RunPod Template:
```
Container Image: wybierz "From GitHub"
GitHub Repo: TWOJA_NAZWA/mrd69-api
Branch: master
Dockerfile Path: Dockerfile.runpod
```

**Opcja B - przez Docker Hub:**
```bash
# Zbuduj lokalnie
docker build -t twoja_nazwa/mrd69-api -f Dockerfile.runpod .

# Push do Docker Hub
docker login
docker push twoja_nazwa/mrd69-api

# W RunPod:
# Container Image: twoja_nazwa/mrd69-api
```

---

### **KROK 5: Uruchom Pod**

1. Kliknij "Pods" â†’ "Deploy"
2. Wybierz swÃ³j template
3. **WAÅ»NE:** Wybierz **CPU** (nie GPU!)
   - Recommended: 2 vCPU, 4GB RAM
4. **Attach Volume:** TAK (10GB) - tu bÄ™dzie baza danych
5. Kliknij "Deploy"

---

### **KROK 6: SprawdÅº czy dziaÅ‚a**

Po ~2 minutach:

1. Kliknij na swÃ³j Pod
2. Zobacz "Connect" â†’ skopiuj URL (bÄ™dzie coÅ› jak: `https://abc123-8000.proxy.runpod.net`)
3. Test:
```bash
curl https://abc123-8000.proxy.runpod.net/api/health
```

**Powinno zwrÃ³ciÄ‡:**
```json
{"ok": true, "mode": "llm", "memory_router": true}
```

**DZIAÅA! ğŸ‰**

---

## ğŸ’° KOSZTY (konkretnie):

### **RunPod CPU Pricing:**
```
SECURE CLOUD (zawsze dostÄ™pne):
- 2 vCPU, 4GB RAM: ~$0.10/h = $72/mies (24/7)
- 4 vCPU, 8GB RAM: ~$0.20/h = $144/mies (24/7)

COMMUNITY CLOUD (taniej, ale moÅ¼e byÄ‡ niedostÄ™pne):
- 2 vCPU, 4GB RAM: ~$0.04/h = $30/mies (24/7)

TWÃ“J BUDÅ»ET: $199
= 2 miesiÄ…ce Secure Cloud
= 6 miesiÄ™cy Community Cloud (jeÅ›li wyÅ‚Ä…czasz nocami)
```

### **Optymalizacja kosztÃ³w:**
```bash
# WÅ‚Ä…cz tylko gdy uÅ¼ywasz:
9:00-22:00 = 13h/dzieÅ„
13h Ã— $0.10 = $1.30/dzieÅ„ = $40/miesiÄ…c

$199 = ~5 miesiÄ™cy dziaÅ‚ania!
```

---

## ğŸ”§ KONFIGURACJA .env NA RUNPOD:

W RunPod Console â†’ TwÃ³j Pod â†’ Environment Variables:

```bash
# LLM (DeepInfra)
LLM_BASE_URL=https://api.deepinfra.com/v1/openai
LLM_API_KEY=<twÃ³j_klucz_deepinfra>
LLM_MODEL=meta-llama/Meta-Llama-3.1-70B-Instruct
LLM_TIMEOUT=30

# RunPod specifics
USE_RUNPOD=1
RUNPOD_PERSIST_DIR=/runpod/persist
MEM_ROOT=/workspace

# Opcjonalnie (jeÅ›li masz):
SERPAPI_KEY=<twÃ³j_klucz>
FIRECRAWL_KEY=<twÃ³j_klucz>
GOOGLE_MAPS_KEY=<twÃ³j_klucz>
```

---

## ğŸ“¡ DOSTÄ˜P DO TWOJEJ APPKI:

Po deployu dostaniesz URL typu:
```
https://abc123xyz-8000.proxy.runpod.net
```

**To jest TWÃ“J publiczny adres!**

MoÅ¼esz:
```
âœ… DaÄ‡ link znajomym
âœ… UÅ¼ywaÄ‡ w innych aplikacjach
âœ… PoÅ‚Ä…czyÄ‡ z frontendem
âœ… DodaÄ‡ wÅ‚asnÄ… domenÄ™
```

---

## ğŸ› ï¸ ZARZÄ„DZANIE PODEM:

### **Start/Stop (oszczÄ™dzaj kasÄ™!):**
```
W RunPod Console:
- "Stop Pod" - zatrzymaj (nie pÅ‚acisz!)
- "Start Pod" - uruchom (pÅ‚acisz od teraz)
```

### **Logs (debugging):**
```
W RunPod Console â†’ TwÃ³j Pod â†’ Logs
Albo przez API
```

### **SSH do poda:**
```
W RunPod Console â†’ TwÃ³j Pod â†’ Connect â†’ "Start Web Terminal"
Albo przez SSH (dajÄ… Ci klucz)
```

---

## ğŸ“Š MONITORING:

### **W RunPod Dashboard zobaczysz:**
```
- CPU usage (powinno byÄ‡ <50%)
- RAM usage (powinno byÄ‡ <2GB)
- Network (ile requestÃ³w)
- Koszty (ile wydaÅ‚eÅ›)
```

---

## ğŸ”¥ ALTERNATYWA: SERVERLESS (jeszcze taniej!)

RunPod ma teÅ¼ **Serverless**:
```
PÅ‚acisz TYLKO gdy uÅ¼ywasz:
- $0.00010/s active time

PrzykÅ‚ad:
100 requestÃ³w/dzieÅ„ Ã— 2s kaÅ¼dy = 200s
200s Ã— $0.0001 = $0.02/dzieÅ„ = $0.60/miesiÄ…c!

$199 = 330 miesiÄ™cy! (27 LAT!) ğŸ˜±
```

Ale wymaga wiÄ™cej setupu - na razie zostaÅ„ przy Pods.

---

## ğŸ¯ QUICK DEPLOY (TL;DR):

```bash
# 1. WrzuÄ‡ kod na GitHub
cd /workspace
git init
git add .
git commit -m "deploy to runpod"
# Push do GitHub (zaÅ‚Ã³Å¼ repo na github.com)

# 2. W RunPod:
# - New Template
# - GitHub integration
# - Deploy CPU Pod (2 vCPU, 4GB RAM)
# - Dodaj zmienne env
# - Deploy!

# 3. Po 2 minutach:
# - Skopiuj URL
# - Test: curl https://twoj-url.runpod.net/api/health

GOTOWE!
```

---

## ğŸ’ª FINAL:

**Za $199 moÅ¼esz mieÄ‡:**
- ~2 miesiÄ…ce 24/7 (Secure Cloud)
- ~5 miesiÄ™cy jeÅ›li wyÅ‚Ä…czasz nocami
- ~6 miesiÄ™cy (Community Cloud)

**Chcesz Å¼ebym pomÃ³gÅ‚ w deployu?** Albo masz juÅ¼ dziaÅ‚ajÄ…ce i chcesz tylko zoptymalizowaÄ‡?
